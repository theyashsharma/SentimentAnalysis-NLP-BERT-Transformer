{"cells":[{"cell_type":"markdown","metadata":{"id":"05KYS_pnO3Dq"},"source":["# Sentiment classification with English Twitter Datasets"]},{"cell_type":"markdown","metadata":{"id":"8_6lr4dbPZNZ"},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":374,"status":"ok","timestamp":1644051145537,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"O2ganP7WOcv-"},"outputs":[],"source":["import os\n","import re\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import csv\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"IpJdkXmSPKfj"},"source":["## 1 ) Loading Datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"E200bW4uv0hW","executionInfo":{"status":"ok","timestamp":1644051147961,"user_tz":-330,"elapsed":4,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"}}},"outputs":[],"source":["df1 = pd.read_csv('tweets_sqgames.csv')\n","df1 = df1.loc[:, ['text', 'sentiment']]\n","label_mapping = {\"Positive\": 1, \"Negative\":0}\n","df1 = df1[df1.sentiment != \"Neutral\"]\n","df1[\"sentiment\"] = df1[\"sentiment\"].map(label_mapping)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"9zdyPvyDv0kq","executionInfo":{"status":"ok","timestamp":1644051148428,"user_tz":-330,"elapsed":470,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"}}},"outputs":[],"source":["df2 = pd.read_csv('Tweets.csv')\n","df2 = df2.loc[:, ['text', 'airline_sentiment']]\n","df2 = df2.rename(columns = {\"airline_sentiment\":\"sentiment\"})\n","label_mapping = {\"positive\": 1, \"negative\":0}\n","df2 = df2[df2.sentiment != \"neutral\"]\n","df2[\"sentiment\"] = df2[\"sentiment\"].map(label_mapping)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wKAkAPNlv0r6","executionInfo":{"status":"ok","timestamp":1644051148429,"user_tz":-330,"elapsed":4,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"}}},"outputs":[],"source":["df3 = pd.read_csv('apple-twitter-sentiment-texts.csv')\n","label_mapping = {1: 1, -1:0}\n","df3 = df3[df3.sentiment != 0]\n","df3[\"sentiment\"] = df3[\"sentiment\"].map(label_mapping)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"f-d6W4F4v0vR","executionInfo":{"status":"ok","timestamp":1644051148824,"user_tz":-330,"elapsed":3,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"}}},"outputs":[],"source":["df4 = pd.read_csv('Apple-Twitter-Sentiment-DFE.csv', encoding=\"Latin-1\")\n","label_mapping = {\"5\": 1, \"1\":0}\n","df4 = df4[df4.sentiment != \"3\"]\n","df4 = df4[df4.sentiment != \"not_relevant\"]\n","df4[\"sentiment\"] = df4[\"sentiment\"].map(label_mapping)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"77x4gFaC6Dry","executionInfo":{"status":"ok","timestamp":1644051149773,"user_tz":-330,"elapsed":2,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"}}},"outputs":[],"source":["df5 = pd.read_csv('Reddit_Data.csv')\n","df5 = df5.rename(columns = {\"clean_comment\":\"text\", \"category\":\"sentiment\"})\n","label_mapping = {1: 1, -1:0}\n","df5 = df5[df5.sentiment != 0]\n","df5[\"sentiment\"] = df5[\"sentiment\"].map(label_mapping)"]},{"cell_type":"code","source":["frames = [df1, df2, df3, df4, df5]\n","merged_df = pd.concat(frames)  "],"metadata":{"id":"A-QAWcnIFcV-","executionInfo":{"status":"ok","timestamp":1644051213452,"user_tz":-330,"elapsed":365,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["merged_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Y8_xeh3EFrlw","executionInfo":{"status":"ok","timestamp":1644051262711,"user_tz":-330,"elapsed":396,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"}},"outputId":"91ba1e11-8711-42c3-84b7-c5ef2728e684"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-8b8027b6-625d-40b2-a1ad-82f23bf8bcea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>When life hits and the same time poverty strik...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>//Blood on 1st slide\\nI'm joining the squidgam...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The two first games, players were killed by th...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>$THG\\nGoing to explode to 4B Marketcap very so...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Please vote in my daily poll. \\nThanks. üòä\\n\\nD...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b8027b6-625d-40b2-a1ad-82f23bf8bcea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8b8027b6-625d-40b2-a1ad-82f23bf8bcea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8b8027b6-625d-40b2-a1ad-82f23bf8bcea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                text  sentiment\n","0  When life hits and the same time poverty strik...          0\n","3  //Blood on 1st slide\\nI'm joining the squidgam...          0\n","4  The two first games, players were killed by th...          0\n","5  $THG\\nGoing to explode to 4B Marketcap very so...          0\n","7  Please vote in my daily poll. \\nThanks. üòä\\n\\nD...          1"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1008,"status":"ok","timestamp":1644051292966,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"M0LtDH9_O1pm"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X = merged_df.text.values\n","y = merged_df.sentiment.values"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1644051295325,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"5H2DVOPHO1sE"},"outputs":[],"source":["X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"]},{"cell_type":"markdown","metadata":{"id":"HakjkIbYY-EZ"},"source":["## 3 ) Deep Learning Approach"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5783,"status":"ok","timestamp":1644051302195,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"-oBZeFVSO2AH","outputId":"03d415d7-b034-4380-8ac9-af39caa72242"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","Device name: Tesla K80\n"]}],"source":["import torch\n","\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13878,"status":"ok","timestamp":1644051316061,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"AI790cijO2GE","outputId":"c519f627-88ac-4748-d992-dbe7024c9259"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.5 MB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 41.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.8 MB 36.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 35.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":674,"status":"ok","timestamp":1644051316729,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"SLMSbnC5O2DJ"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModel"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2750,"status":"ok","timestamp":1644051319461,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"xMmgFGdOO2Jh","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["71c2961396874a4296d1b4de7e15f250","f78c2825bac048cd950824eedf71824f","adff7bf391134c49bc5af8ed7a07092d","cfa07037637647afae8ce46993aca7e2","44e7d035409543fea94faac7579bf944","c22ee813fac64756ad5670fc157e92c4","693a83155c05429ea70db61040a58903","865e92058ee542aaa56bbe507c85f831","baa013b5198643faa2faa554eb3ad3d7","db48f02c469049da8e0a46e446f58506","70b126751bde476eb3e2e2447467d390","5a0f4e92c0cd4123b59f8a1f87a1e5da","96813cd0c45542f5b4afe937e1a31a0e","8027d770e628447da3a5960c8311ae36","94247be1e65d4618963bcd128caab47c","081d6b3f235346c39250d191787f077b","05dc92ff0a874c74874fa90683f29ccc","b5a79320595b4758a3bb1ce7fc9a6339","2508efa658dc4f24a6ba4486464d60a4","ef917737d907401588cbc8e396cfcb46","630f95f1e6104c7d9206c26be8d20007","0b14daf1a34a4816b4b57ac88f68ee7c","169b426e31204bfc898e66554505fa85","2e41096f62f9421bb9b4b2a6fba2d5c4","5809b462ca70442b8809a9a88adc58a9","37b2a0386ea140dd9132bd87603c5da4","ecfbb650bd834d3798bae228526c303e","e8fb9d418f5e439ea0324820e1e0dfed","10b31874aca54be3b20c70b093305ffa","51543c0dceff4ae5b1f3017e040fccd5","379ff5ccdbd048a4894fd5c039564fa6","400c09fbfb314b3280fbb7c94da6a948","be059c65f77541d3b0b727673ef902a9","f5ed451092334bfeaa580ad2643143d3","33dac5ea76134613b34d9c950539ad8f","ee04d865572142988416c855d6737c5a","aca390e6630f4a81bfa4a20016823bd2","7a824931c883424ea13d0e1ad8f6f2ea","3db3dfe2405a4742994073a77eee0751","608fe6a7a3c4425fabca53ada98f2eff","c8aabe8055214bf8bad9596872950f7f","56692ad6b00d44a7b621f809d592eed8","be7d88eebcc34a7f8791557c88f3d96f","238435899b5d4c6c8818f5fbeb303502"]},"outputId":"62f3177f-cb8c-4133-c7b5-d24791512309"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71c2961396874a4296d1b4de7e15f250","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a0f4e92c0cd4123b59f8a1f87a1e5da","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/768 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"169b426e31204bfc898e66554505fa85","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5ed451092334bfeaa580ad2643143d3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1644051319462,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"o2TenWCGZw7I"},"outputs":[],"source":["def text_preprocessing(text):\n","    \"\"\"\n","    - Remove entity mentions (eg. '@united')\n","    - Correct errors (eg. '&amp;' to '&')\n","    @param    text (str): a string to be processed.\n","    @return   text (Str): the processed string.\n","    \"\"\"\n","\n","    # Normalize unicode encoding\n","    text = unicodedata.normalize('NFC', text)\n","    # Remove '@name'\n","    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n","\n","    # Replace '&amp;' with '&'\n","    text = re.sub(r'&amp;', '&', text)\n","\n","    # Remove trailing whitespace\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    #Remove URLs\n","    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '<URL>', text)\n","\n","\n","    return text"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1644051319463,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"Lp6sDjV9L2hQ"},"outputs":[],"source":["def remove_emojis(sent):\n","    text =  emoji.demojize(sent)\n","    text= re.sub(r'(:[!_\\-\\w]+:)', '', text)\n","    return text\n","    \n","def text_preprocessing_no_emojis(text):\n","    \"\"\"\n","    - Remove entity mentions (eg. '@united')\n","    - Correct errors (eg. '&amp;' to '&')\n","    @param    text (str): a string to be processed.\n","    @return   text (Str): the processed string.\n","    \"\"\"\n","  \n","    # Remove emojis\n","    text = remove_emojis(text)\n","\n","    return text_preprocessing(text)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5251,"status":"ok","timestamp":1644051324697,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"gklJcuwha7hu","outputId":"3ef51cac-4923-45ca-de27-c804d24b724b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-1.6.3.tar.gz (174 kB)\n","\u001b[?25l\r\u001b[K     |‚ñà‚ñâ                              | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñä                            | 20 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174 kB 5.3 MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=9ce2d51a383bd543d52ecadb5e25067669180c740171290db94e30b5e44671c9\n","  Stored in directory: /root/.cache/pip/wheels/03/8b/d7/ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-1.6.3\n"]}],"source":["!pip install emoji"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":653,"status":"ok","timestamp":1644051325345,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"8fjl5AftaQU7"},"outputs":[],"source":["import emoji\n","import unicodedata\n","def preprocessing_for_bert(data, version=\"mini\", text_preprocessing_fn = text_preprocessing):\n","    \"\"\"Perform required preprocessing steps for pretrained BERT.\n","    @param    data (np.array): Array of texts to be processed.\n","    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n","    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n","                  tokens should be attended to by the model.\n","    \"\"\"\n","    # Create empty lists to store outputs\n","    input_ids = []\n","    attention_masks = []\n","    tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")# if version == \"mini\" else AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n","\n","    # For every sentence...\n","    for i,sent in enumerate(data):\n","        # `encode_plus` will:\n","        #    (1) Tokenize the sentence\n","        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n","        #    (3) Truncate/Pad sentence to max length\n","        #    (4) Map tokens to their IDs\n","        #    (5) Create attention mask\n","        #    (6) Return a dictionary of outputs\n","        encoded_sent = tokenizer.encode_plus(\n","            text=text_preprocessing_fn(sent),  # Preprocess sentence\n","            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n","            max_length=MAX_LEN,                  # Max length to truncate/pad\n","            padding='max_length',        # Pad sentence to max length\n","            #return_tensors='pt',           # Return PyTorch tensor\n","            return_attention_mask=True,     # Return attention mask\n","            truncation = True \n","            )\n","        \n","        # Add the outputs to the lists\n","        input_ids.append(encoded_sent.get('input_ids'))\n","        attention_masks.append(encoded_sent.get('attention_mask'))\n","    # Convert lists to tensors\n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","\n","    return input_ids, attention_masks"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44594,"status":"ok","timestamp":1644051369926,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"PCm99bITa5hL","outputId":"d64b8c18-55de-4209-b215-41c9b8b751d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  When life hits and the same time poverty strikes you\n","Gong Yoo : Lets play a game \n","#SquidGame #Netflix https://t.co/Cx7ifmZ8cN\n","Token IDs:  [101, 2043, 2166, 4978, 1998, 1996, 2168, 2051, 5635, 9326, 2017, 17242, 26823, 1024, 11082, 2377, 1037, 2208, 1001, 26852, 16650, 1001, 20907, 16770, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 1039, 2595, 2581, 10128, 2213, 2480, 2620, 2278, 2078, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Tokenizing data...\n"]}],"source":["# Specify `MAX_LEN`\n","MAX_LEN =  280\n","\n","# Print sentence 0 and its encoded token ids\n","token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n","print('Original: ', X[0])\n","print('Token IDs: ', token_ids)\n","\n","# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n","val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1644051369926,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"U7iTT16LbLni"},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 16\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1644051369927,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"32gvSQ9pb9Fr","outputId":"b40396b1-fa87-4cf9-eace-94bc7db9c7c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 28.8 ms, sys: 2 ms, total: 30.7 ms\n","Wall time: 31.8 ms\n"]}],"source":["%%time\n","import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","# Create the BertClassfier class\n","class BertClassifier(nn.Module):\n","    \"\"\"Bert Model for Classification Tasks.\n","    \"\"\"\n","    def __init__(self, freeze_bert=False, version=\"mini\"):\n","        \"\"\"\n","        @param    bert: a BertModel object\n","        @param    classifier: a torch.nn.Module classifier\n","        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n","        \"\"\"\n","        super(BertClassifier, self).__init__()\n","        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n","        D_in = 768\n","        H, D_out = 50, 2\n","\n","        # Instantiate BERT model\n","        self.bert = AutoModel.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")\n","        self.lstm = nn.LSTM(768, 768, bidirectional=True)\n","        # Instantiate an one-layer feed-forward classifier\n","        self.classifier = nn.Sequential(\n","\n","            nn.Linear(D_in, H),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(H, D_out)\n","        )\n","\n","        # Freeze the BERT model\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","        \n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","        Feed input to BERT and the classifier to compute logits.\n","        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n","                      max_length)\n","        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n","                      information with shape (batch_size, max_length)\n","        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n","                      num_labels)\n","        \"\"\"\n","        # Feed input to BERT\n","        outputs = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask)\n","        \n","        # Extract the last hidden state of the token `[CLS]` for classification task\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","\n","        # Feed input to classifier to compute logits\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":3431,"status":"ok","timestamp":1644051373354,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"z7RwU_UBPHUh"},"outputs":[],"source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","from torch.optim import SparseAdam, Adam\n","def initialize_model(epochs=4, version=\"base\"):\n","    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n","    \"\"\"\n","    # Instantiate Bert Classifier\n","    bert_classifier = BertClassifier(freeze_bert=False, version=version)\n","    # Tell PyTorch to run the model on GPU\n","    bert_classifier.to(device)\n","\n","    # Create the optimizer\n","    optimizer = torch.optim.AdamW(params=list(bert_classifier.parameters()),\n","                      lr=5e-5,    # Default learning rate\n","                      eps=1e-8    # Default epsilon value\n","                      )\n","\n","    # Total number of training steps\n","    total_steps = len(train_dataloader) * epochs\n","\n","    # Set up the learning rate scheduler\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0, # Default value\n","                                                num_training_steps=total_steps)\n","    return bert_classifier, optimizer, scheduler"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1644051373354,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"DwlxCFVUPHXN"},"outputs":[],"source":["import random\n","import time\n","import torch\n","import torch.nn as nn\n","\n","# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.\n","    \"\"\"\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n","    \"\"\"Train the BertClassifier model.\n","    \"\"\"\n","    # Start training loop\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        # =======================================\n","        #               Training\n","        # =======================================\n","        # Print the header of the result table\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*70)\n","\n","        # Measure the elapsed time of each epoch\n","        t0_epoch, t0_batch = time.time(), time.time()\n","\n","        # Reset tracking variables at the beginning of each epoch\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","\n","        # Put the model into the training mode\n","        model.train()\n","\n","        # For each batch of training data...\n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # Load batch to GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","            # Zero out any previously calculated gradients\n","            model.zero_grad()\n","\n","            # Perform a forward pass. This will return logits.\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","            # Compute loss and accumulate the loss values\n","            loss = loss_fn(logits, b_labels)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","\n","            # Perform a backward pass to calculate gradients\n","            loss.backward()\n","\n","            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            # Update parameters and the learning rate\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Print the loss values and time elapsed for every 20 batches\n","            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # Calculate time elapsed for 20 batches\n","                time_elapsed = time.time() - t0_batch\n","\n","                # Print training results\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n","\n","                # Reset batch tracking variables\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","\n","        # Calculate the average loss over the entire training data\n","        avg_train_loss = total_loss / len(train_dataloader)\n","\n","        print(\"-\"*70)\n","        # =======================================\n","        #               Evaluation\n","        # =======================================\n","        if evaluation == True:\n","            # After the completion of each training epoch, measure the model's performance\n","            # on our validation set.\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","\n","            # Print performance over the entire training data\n","            time_elapsed = time.time() - t0_epoch\n","            \n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*70)\n","        print(\"\\n\")\n","    \n","    print(\"Training complete!\")\n","\n","def evaluate(model, val_dataloader):\n","    \"\"\"After the completion of each training epoch, measure the model's performance\n","    on our validation set.\n","    \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    # Tracking variables\n","    val_accuracy = []\n","    val_loss = []\n","\n","    # For each batch in our validation set...\n","    for batch in val_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","        # Compute loss\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","\n","        # Get the predictions\n","        preds = torch.argmax(logits, dim=1).flatten()\n","\n","        # Calculate the accuracy rate\n","        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n","        val_accuracy.append(accuracy)\n","\n","       \n","\n","    # Compute the average accuracy and loss over the validation set.\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","\n","    return val_loss, val_accuracy"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["39634959f860454196b892cf99966c56","6f2092e24eb54ceb902020c1f9c3e464","8d8a0280949e41c3abda066c85bbde1b","b567b18b9b0e40e1bcb775617b425c78","94350f53691b4c53b08292e659ad0151","3aafedaab5f84566919fe77c04c531ad","7a65d770e0e24be186f77eab8a470826","09aa4986e7f14f44a37471e72ae21b8e","9e472aaab4af4ae88b8632ea23d91270","0c7ddfba658843619d43c8ccfb8a49ed","cbc10230dcd943e8ab88146d89116fb9"]},"executionInfo":{"elapsed":6470576,"status":"ok","timestamp":1644057843926,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"I0K_YbfyO1TR","outputId":"6d7364e9-7cc4-443f-e0b6-ebe2dedf18ff"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39634959f860454196b892cf99966c56","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion were not used when initializing DistilBertModel: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   1    |   20    |   0.597286   |     -      |     -     |   16.61  \n","   1    |   40    |   0.620863   |     -      |     -     |   15.45  \n","   1    |   60    |   0.518196   |     -      |     -     |   15.58  \n","   1    |   80    |   0.439558   |     -      |     -     |   15.59  \n","   1    |   100   |   0.448506   |     -      |     -     |   15.54  \n","   1    |   120   |   0.445326   |     -      |     -     |   15.64  \n","   1    |   140   |   0.453780   |     -      |     -     |   15.88  \n","   1    |   160   |   0.425546   |     -      |     -     |   15.71  \n","   1    |   180   |   0.378503   |     -      |     -     |   15.52  \n","   1    |   200   |   0.380186   |     -      |     -     |   15.50  \n","   1    |   220   |   0.390688   |     -      |     -     |   15.53  \n","   1    |   240   |   0.365451   |     -      |     -     |   15.50  \n","   1    |   260   |   0.378681   |     -      |     -     |   15.50  \n","   1    |   280   |   0.335631   |     -      |     -     |   15.51  \n","   1    |   300   |   0.299576   |     -      |     -     |   15.55  \n","   1    |   320   |   0.304356   |     -      |     -     |   15.56  \n","   1    |   340   |   0.339464   |     -      |     -     |   15.62  \n","   1    |   360   |   0.322211   |     -      |     -     |   15.60  \n","   1    |   380   |   0.299193   |     -      |     -     |   15.59  \n","   1    |   400   |   0.337880   |     -      |     -     |   15.61  \n","   1    |   420   |   0.304900   |     -      |     -     |   15.63  \n","   1    |   440   |   0.373609   |     -      |     -     |   15.62  \n","   1    |   460   |   0.316151   |     -      |     -     |   15.61  \n","   1    |   480   |   0.364205   |     -      |     -     |   15.58  \n","   1    |   500   |   0.313643   |     -      |     -     |   15.60  \n","   1    |   520   |   0.372237   |     -      |     -     |   15.61  \n","   1    |   540   |   0.346405   |     -      |     -     |   15.63  \n","   1    |   560   |   0.208390   |     -      |     -     |   15.63  \n","   1    |   580   |   0.259916   |     -      |     -     |   15.75  \n","   1    |   600   |   0.317263   |     -      |     -     |   15.59  \n","   1    |   620   |   0.336205   |     -      |     -     |   15.62  \n","   1    |   640   |   0.321998   |     -      |     -     |   15.61  \n","   1    |   660   |   0.286406   |     -      |     -     |   15.56  \n","   1    |   680   |   0.260043   |     -      |     -     |   15.59  \n","   1    |   700   |   0.272260   |     -      |     -     |   15.62  \n","   1    |   720   |   0.273898   |     -      |     -     |   15.58  \n","   1    |   740   |   0.354122   |     -      |     -     |   15.61  \n","   1    |   760   |   0.197632   |     -      |     -     |   15.57  \n","   1    |   780   |   0.249574   |     -      |     -     |   15.60  \n","   1    |   800   |   0.301435   |     -      |     -     |   15.60  \n","   1    |   820   |   0.204162   |     -      |     -     |   15.58  \n","   1    |   840   |   0.326407   |     -      |     -     |   15.60  \n","   1    |   860   |   0.295146   |     -      |     -     |   15.58  \n","   1    |   880   |   0.217463   |     -      |     -     |   15.62  \n","   1    |   900   |   0.318250   |     -      |     -     |   15.60  \n","   1    |   920   |   0.210996   |     -      |     -     |   15.57  \n","   1    |   940   |   0.347147   |     -      |     -     |   15.59  \n","   1    |   960   |   0.184991   |     -      |     -     |   15.61  \n","   1    |   980   |   0.356308   |     -      |     -     |   15.59  \n","   1    |  1000   |   0.321850   |     -      |     -     |   15.61  \n","   1    |  1020   |   0.213072   |     -      |     -     |   15.59  \n","   1    |  1040   |   0.274440   |     -      |     -     |   15.61  \n","   1    |  1060   |   0.235304   |     -      |     -     |   15.59  \n","   1    |  1080   |   0.351669   |     -      |     -     |   15.59  \n","   1    |  1100   |   0.288607   |     -      |     -     |   15.57  \n","   1    |  1120   |   0.206459   |     -      |     -     |   15.54  \n","   1    |  1140   |   0.350708   |     -      |     -     |   15.51  \n","   1    |  1160   |   0.265489   |     -      |     -     |   15.49  \n","   1    |  1180   |   0.255427   |     -      |     -     |   15.50  \n","   1    |  1200   |   0.217435   |     -      |     -     |   15.53  \n","   1    |  1220   |   0.218996   |     -      |     -     |   15.48  \n","   1    |  1240   |   0.253955   |     -      |     -     |   15.50  \n","   1    |  1260   |   0.219866   |     -      |     -     |   15.50  \n","   1    |  1280   |   0.200415   |     -      |     -     |   15.51  \n","   1    |  1300   |   0.235683   |     -      |     -     |   15.52  \n","   1    |  1320   |   0.244642   |     -      |     -     |   15.50  \n","   1    |  1340   |   0.232904   |     -      |     -     |   15.49  \n","   1    |  1360   |   0.266493   |     -      |     -     |   15.49  \n","   1    |  1380   |   0.275094   |     -      |     -     |   15.49  \n","   1    |  1400   |   0.245223   |     -      |     -     |   15.53  \n","   1    |  1420   |   0.222764   |     -      |     -     |   15.53  \n","   1    |  1440   |   0.181797   |     -      |     -     |   15.58  \n","   1    |  1460   |   0.221429   |     -      |     -     |   15.61  \n","   1    |  1480   |   0.241652   |     -      |     -     |   15.61  \n","   1    |  1500   |   0.204234   |     -      |     -     |   15.60  \n","   1    |  1520   |   0.169128   |     -      |     -     |   15.61  \n","   1    |  1540   |   0.214569   |     -      |     -     |   15.59  \n","   1    |  1560   |   0.303257   |     -      |     -     |   15.62  \n","   1    |  1580   |   0.171790   |     -      |     -     |   15.62  \n","   1    |  1600   |   0.236314   |     -      |     -     |   15.61  \n","   1    |  1620   |   0.214638   |     -      |     -     |   15.68  \n","   1    |  1640   |   0.204486   |     -      |     -     |   15.67  \n","   1    |  1660   |   0.227295   |     -      |     -     |   15.66  \n","   1    |  1680   |   0.267204   |     -      |     -     |   15.68  \n","   1    |  1700   |   0.173554   |     -      |     -     |   15.61  \n","   1    |  1720   |   0.250551   |     -      |     -     |   15.57  \n","   1    |  1740   |   0.251446   |     -      |     -     |   15.53  \n","   1    |  1760   |   0.252300   |     -      |     -     |   15.51  \n","   1    |  1780   |   0.167891   |     -      |     -     |   15.51  \n","   1    |  1800   |   0.235727   |     -      |     -     |   15.50  \n","   1    |  1820   |   0.216368   |     -      |     -     |   15.49  \n","   1    |  1840   |   0.247357   |     -      |     -     |   15.49  \n","   1    |  1860   |   0.155827   |     -      |     -     |   15.50  \n","   1    |  1880   |   0.304703   |     -      |     -     |   15.52  \n","   1    |  1900   |   0.267598   |     -      |     -     |   15.49  \n","   1    |  1920   |   0.189356   |     -      |     -     |   15.49  \n","   1    |  1940   |   0.180405   |     -      |     -     |   15.49  \n","   1    |  1960   |   0.186523   |     -      |     -     |   15.50  \n","   1    |  1980   |   0.208720   |     -      |     -     |   15.51  \n","   1    |  2000   |   0.232629   |     -      |     -     |   15.49  \n","   1    |  2020   |   0.265415   |     -      |     -     |   15.50  \n","   1    |  2040   |   0.174326   |     -      |     -     |   15.48  \n","   1    |  2060   |   0.200959   |     -      |     -     |   15.52  \n","   1    |  2080   |   0.165976   |     -      |     -     |   15.50  \n","   1    |  2100   |   0.205795   |     -      |     -     |   15.51  \n","   1    |  2120   |   0.196179   |     -      |     -     |   15.49  \n","   1    |  2140   |   0.195276   |     -      |     -     |   15.51  \n","   1    |  2160   |   0.209003   |     -      |     -     |   15.51  \n","   1    |  2180   |   0.194569   |     -      |     -     |   15.49  \n","   1    |  2200   |   0.230766   |     -      |     -     |   15.50  \n","   1    |  2220   |   0.238819   |     -      |     -     |   15.50  \n","   1    |  2240   |   0.199380   |     -      |     -     |   15.51  \n","   1    |  2260   |   0.150439   |     -      |     -     |   15.52  \n","   1    |  2280   |   0.165803   |     -      |     -     |   15.49  \n","   1    |  2300   |   0.295614   |     -      |     -     |   15.48  \n","   1    |  2320   |   0.249035   |     -      |     -     |   15.51  \n","   1    |  2340   |   0.207270   |     -      |     -     |   15.51  \n","   1    |  2360   |   0.316743   |     -      |     -     |   15.51  \n","   1    |  2380   |   0.266944   |     -      |     -     |   15.54  \n","   1    |  2400   |   0.190899   |     -      |     -     |   15.52  \n","   1    |  2420   |   0.252763   |     -      |     -     |   15.49  \n","   1    |  2440   |   0.175542   |     -      |     -     |   15.50  \n","   1    |  2460   |   0.211391   |     -      |     -     |   15.49  \n","   1    |  2480   |   0.216576   |     -      |     -     |   15.50  \n","   1    |  2500   |   0.198886   |     -      |     -     |   15.50  \n","   1    |  2520   |   0.186438   |     -      |     -     |   15.54  \n","   1    |  2540   |   0.229287   |     -      |     -     |   15.53  \n","   1    |  2560   |   0.130728   |     -      |     -     |   15.49  \n","   1    |  2580   |   0.232426   |     -      |     -     |   15.52  \n","   1    |  2600   |   0.181770   |     -      |     -     |   15.53  \n","   1    |  2620   |   0.210153   |     -      |     -     |   15.52  \n","   1    |  2640   |   0.226453   |     -      |     -     |   15.53  \n","   1    |  2660   |   0.223000   |     -      |     -     |   15.51  \n","   1    |  2680   |   0.252451   |     -      |     -     |   15.53  \n","   1    |  2700   |   0.172527   |     -      |     -     |   15.51  \n","   1    |  2720   |   0.222221   |     -      |     -     |   15.50  \n","   1    |  2740   |   0.222846   |     -      |     -     |   15.51  \n","   1    |  2760   |   0.154448   |     -      |     -     |   15.50  \n","   1    |  2780   |   0.202769   |     -      |     -     |   15.52  \n","   1    |  2800   |   0.329427   |     -      |     -     |   15.50  \n","   1    |  2820   |   0.203471   |     -      |     -     |   15.49  \n","   1    |  2840   |   0.176223   |     -      |     -     |   15.50  \n","   1    |  2860   |   0.205033   |     -      |     -     |   15.50  \n","   1    |  2880   |   0.209500   |     -      |     -     |   15.52  \n","   1    |  2900   |   0.169564   |     -      |     -     |   15.52  \n","   1    |  2920   |   0.179635   |     -      |     -     |   15.50  \n","   1    |  2940   |   0.203611   |     -      |     -     |   15.52  \n","   1    |  2960   |   0.160043   |     -      |     -     |   15.50  \n","   1    |  2980   |   0.157516   |     -      |     -     |   15.49  \n","   1    |  3000   |   0.226327   |     -      |     -     |   15.49  \n","   1    |  3020   |   0.244267   |     -      |     -     |   15.50  \n","   1    |  3040   |   0.177841   |     -      |     -     |   15.50  \n","   1    |  3060   |   0.142502   |     -      |     -     |   15.51  \n","   1    |  3080   |   0.162028   |     -      |     -     |   15.52  \n","   1    |  3100   |   0.179942   |     -      |     -     |   15.51  \n","   1    |  3120   |   0.162444   |     -      |     -     |   15.49  \n","   1    |  3140   |   0.199264   |     -      |     -     |   15.49  \n","   1    |  3160   |   0.205195   |     -      |     -     |   15.51  \n","   1    |  3180   |   0.139316   |     -      |     -     |   15.51  \n","   1    |  3200   |   0.167058   |     -      |     -     |   15.49  \n","   1    |  3220   |   0.171462   |     -      |     -     |   15.48  \n","   1    |  3240   |   0.214545   |     -      |     -     |   15.49  \n","   1    |  3260   |   0.095135   |     -      |     -     |   15.52  \n","   1    |  3280   |   0.197489   |     -      |     -     |   15.58  \n","   1    |  3300   |   0.162907   |     -      |     -     |   15.61  \n","   1    |  3320   |   0.151684   |     -      |     -     |   15.61  \n","   1    |  3340   |   0.247897   |     -      |     -     |   15.58  \n","   1    |  3360   |   0.194955   |     -      |     -     |   15.61  \n","   1    |  3380   |   0.204728   |     -      |     -     |   15.62  \n","   1    |  3400   |   0.151761   |     -      |     -     |   15.61  \n","   1    |  3420   |   0.183380   |     -      |     -     |   15.61  \n","   1    |  3440   |   0.159808   |     -      |     -     |   15.61  \n","   1    |  3460   |   0.189609   |     -      |     -     |   15.63  \n","   1    |  3480   |   0.180158   |     -      |     -     |   15.60  \n","   1    |  3500   |   0.149973   |     -      |     -     |   15.64  \n","   1    |  3520   |   0.151827   |     -      |     -     |   15.66  \n","   1    |  3540   |   0.161822   |     -      |     -     |   15.69  \n","   1    |  3560   |   0.269103   |     -      |     -     |   15.68  \n","   1    |  3580   |   0.165202   |     -      |     -     |   15.68  \n","   1    |  3600   |   0.126591   |     -      |     -     |   15.68  \n","   1    |  3620   |   0.199635   |     -      |     -     |   15.69  \n","   1    |  3640   |   0.239232   |     -      |     -     |   15.68  \n","   1    |  3660   |   0.194047   |     -      |     -     |   15.67  \n","   1    |  3680   |   0.158731   |     -      |     -     |   15.68  \n","   1    |  3700   |   0.156013   |     -      |     -     |   15.68  \n","   1    |  3720   |   0.225349   |     -      |     -     |   15.68  \n","   1    |  3740   |   0.208891   |     -      |     -     |   15.68  \n","   1    |  3760   |   0.199424   |     -      |     -     |   15.71  \n","   1    |  3780   |   0.207743   |     -      |     -     |   15.68  \n","   1    |  3800   |   0.240855   |     -      |     -     |   15.69  \n","   1    |  3820   |   0.213550   |     -      |     -     |   15.77  \n","   1    |  3840   |   0.237787   |     -      |     -     |   15.73  \n","   1    |  3860   |   0.144492   |     -      |     -     |   15.66  \n","   1    |  3880   |   0.150429   |     -      |     -     |   15.68  \n","   1    |  3900   |   0.175491   |     -      |     -     |   15.68  \n","   1    |  3920   |   0.215853   |     -      |     -     |   15.68  \n","   1    |  3940   |   0.213528   |     -      |     -     |   15.68  \n","   1    |  3950   |   0.100252   |     -      |     -     |   7.86   \n","----------------------------------------------------------------------\n","   1    |    -    |   0.241764   |  0.162304  |   94.15   |  3201.81 \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   2    |   20    |   0.123088   |     -      |     -     |   16.45  \n","   2    |   40    |   0.119897   |     -      |     -     |   15.66  \n","   2    |   60    |   0.122192   |     -      |     -     |   15.69  \n","   2    |   80    |   0.128312   |     -      |     -     |   15.65  \n","   2    |   100   |   0.108141   |     -      |     -     |   15.67  \n","   2    |   120   |   0.080921   |     -      |     -     |   15.67  \n","   2    |   140   |   0.111685   |     -      |     -     |   15.66  \n","   2    |   160   |   0.110764   |     -      |     -     |   15.68  \n","   2    |   180   |   0.093945   |     -      |     -     |   15.68  \n","   2    |   200   |   0.119236   |     -      |     -     |   15.68  \n","   2    |   220   |   0.114397   |     -      |     -     |   15.68  \n","   2    |   240   |   0.111499   |     -      |     -     |   15.69  \n","   2    |   260   |   0.137274   |     -      |     -     |   15.70  \n","   2    |   280   |   0.130573   |     -      |     -     |   15.66  \n","   2    |   300   |   0.121591   |     -      |     -     |   15.66  \n","   2    |   320   |   0.069716   |     -      |     -     |   15.67  \n","   2    |   340   |   0.261520   |     -      |     -     |   15.69  \n","   2    |   360   |   0.128390   |     -      |     -     |   15.68  \n","   2    |   380   |   0.110317   |     -      |     -     |   15.67  \n","   2    |   400   |   0.166926   |     -      |     -     |   15.68  \n","   2    |   420   |   0.110637   |     -      |     -     |   15.67  \n","   2    |   440   |   0.102921   |     -      |     -     |   15.71  \n","   2    |   460   |   0.172080   |     -      |     -     |   15.68  \n","   2    |   480   |   0.186771   |     -      |     -     |   15.68  \n","   2    |   500   |   0.101126   |     -      |     -     |   15.66  \n","   2    |   520   |   0.099178   |     -      |     -     |   15.67  \n","   2    |   540   |   0.108971   |     -      |     -     |   15.68  \n","   2    |   560   |   0.157843   |     -      |     -     |   15.68  \n","   2    |   580   |   0.064732   |     -      |     -     |   15.68  \n","   2    |   600   |   0.134783   |     -      |     -     |   15.68  \n","   2    |   620   |   0.077463   |     -      |     -     |   15.64  \n","   2    |   640   |   0.120608   |     -      |     -     |   15.68  \n","   2    |   660   |   0.104845   |     -      |     -     |   15.68  \n","   2    |   680   |   0.111281   |     -      |     -     |   15.69  \n","   2    |   700   |   0.158701   |     -      |     -     |   15.66  \n","   2    |   720   |   0.121555   |     -      |     -     |   15.68  \n","   2    |   740   |   0.058025   |     -      |     -     |   15.68  \n","   2    |   760   |   0.152221   |     -      |     -     |   15.67  \n","   2    |   780   |   0.084764   |     -      |     -     |   15.67  \n","   2    |   800   |   0.125395   |     -      |     -     |   15.68  \n","   2    |   820   |   0.133894   |     -      |     -     |   15.68  \n","   2    |   840   |   0.109118   |     -      |     -     |   15.68  \n","   2    |   860   |   0.157049   |     -      |     -     |   15.67  \n","   2    |   880   |   0.079680   |     -      |     -     |   15.70  \n","   2    |   900   |   0.105324   |     -      |     -     |   15.67  \n","   2    |   920   |   0.108883   |     -      |     -     |   15.67  \n","   2    |   940   |   0.104787   |     -      |     -     |   15.69  \n","   2    |   960   |   0.194018   |     -      |     -     |   15.67  \n","   2    |   980   |   0.085329   |     -      |     -     |   15.67  \n","   2    |  1000   |   0.118783   |     -      |     -     |   15.66  \n","   2    |  1020   |   0.139820   |     -      |     -     |   15.65  \n","   2    |  1040   |   0.099804   |     -      |     -     |   15.67  \n","   2    |  1060   |   0.104287   |     -      |     -     |   15.68  \n","   2    |  1080   |   0.165767   |     -      |     -     |   15.68  \n","   2    |  1100   |   0.071557   |     -      |     -     |   15.66  \n","   2    |  1120   |   0.218917   |     -      |     -     |   15.67  \n","   2    |  1140   |   0.119960   |     -      |     -     |   15.65  \n","   2    |  1160   |   0.073304   |     -      |     -     |   15.66  \n","   2    |  1180   |   0.119221   |     -      |     -     |   15.64  \n","   2    |  1200   |   0.138107   |     -      |     -     |   15.66  \n","   2    |  1220   |   0.117024   |     -      |     -     |   15.66  \n","   2    |  1240   |   0.111608   |     -      |     -     |   15.66  \n","   2    |  1260   |   0.090173   |     -      |     -     |   15.66  \n","   2    |  1280   |   0.103031   |     -      |     -     |   15.68  \n","   2    |  1300   |   0.161209   |     -      |     -     |   15.65  \n","   2    |  1320   |   0.064441   |     -      |     -     |   15.68  \n","   2    |  1340   |   0.059110   |     -      |     -     |   15.66  \n","   2    |  1360   |   0.125193   |     -      |     -     |   15.66  \n","   2    |  1380   |   0.104829   |     -      |     -     |   15.70  \n","   2    |  1400   |   0.118929   |     -      |     -     |   15.68  \n","   2    |  1420   |   0.128647   |     -      |     -     |   15.65  \n","   2    |  1440   |   0.131468   |     -      |     -     |   15.66  \n","   2    |  1460   |   0.122531   |     -      |     -     |   15.67  \n","   2    |  1480   |   0.116375   |     -      |     -     |   15.67  \n","   2    |  1500   |   0.152469   |     -      |     -     |   15.66  \n","   2    |  1520   |   0.083723   |     -      |     -     |   15.66  \n","   2    |  1540   |   0.069944   |     -      |     -     |   15.60  \n","   2    |  1560   |   0.166252   |     -      |     -     |   15.59  \n","   2    |  1580   |   0.148882   |     -      |     -     |   15.61  \n","   2    |  1600   |   0.175492   |     -      |     -     |   15.66  \n","   2    |  1620   |   0.076109   |     -      |     -     |   15.63  \n","   2    |  1640   |   0.057750   |     -      |     -     |   15.64  \n","   2    |  1660   |   0.069014   |     -      |     -     |   15.64  \n","   2    |  1680   |   0.107066   |     -      |     -     |   15.68  \n","   2    |  1700   |   0.151050   |     -      |     -     |   15.68  \n","   2    |  1720   |   0.179980   |     -      |     -     |   15.66  \n","   2    |  1740   |   0.187736   |     -      |     -     |   15.68  \n","   2    |  1760   |   0.107133   |     -      |     -     |   15.68  \n","   2    |  1780   |   0.109915   |     -      |     -     |   15.68  \n","   2    |  1800   |   0.088082   |     -      |     -     |   15.68  \n","   2    |  1820   |   0.115117   |     -      |     -     |   15.69  \n","   2    |  1840   |   0.125582   |     -      |     -     |   15.68  \n","   2    |  1860   |   0.101577   |     -      |     -     |   15.66  \n","   2    |  1880   |   0.108077   |     -      |     -     |   15.67  \n","   2    |  1900   |   0.064541   |     -      |     -     |   15.67  \n","   2    |  1920   |   0.116622   |     -      |     -     |   15.68  \n","   2    |  1940   |   0.095699   |     -      |     -     |   15.66  \n","   2    |  1960   |   0.114959   |     -      |     -     |   15.67  \n","   2    |  1980   |   0.174337   |     -      |     -     |   15.67  \n","   2    |  2000   |   0.111199   |     -      |     -     |   15.66  \n","   2    |  2020   |   0.048938   |     -      |     -     |   15.67  \n","   2    |  2040   |   0.137192   |     -      |     -     |   15.68  \n","   2    |  2060   |   0.111094   |     -      |     -     |   15.66  \n","   2    |  2080   |   0.167680   |     -      |     -     |   15.69  \n","   2    |  2100   |   0.089328   |     -      |     -     |   15.67  \n","   2    |  2120   |   0.139926   |     -      |     -     |   15.67  \n","   2    |  2140   |   0.138601   |     -      |     -     |   15.68  \n","   2    |  2160   |   0.098506   |     -      |     -     |   15.66  \n","   2    |  2180   |   0.161042   |     -      |     -     |   15.67  \n","   2    |  2200   |   0.097904   |     -      |     -     |   15.67  \n","   2    |  2220   |   0.122955   |     -      |     -     |   15.70  \n","   2    |  2240   |   0.122007   |     -      |     -     |   15.69  \n","   2    |  2260   |   0.091071   |     -      |     -     |   15.67  \n","   2    |  2280   |   0.061097   |     -      |     -     |   15.69  \n","   2    |  2300   |   0.164757   |     -      |     -     |   15.68  \n","   2    |  2320   |   0.090220   |     -      |     -     |   15.66  \n","   2    |  2340   |   0.092366   |     -      |     -     |   15.67  \n","   2    |  2360   |   0.073896   |     -      |     -     |   15.67  \n","   2    |  2380   |   0.187046   |     -      |     -     |   15.67  \n","   2    |  2400   |   0.092368   |     -      |     -     |   15.70  \n","   2    |  2420   |   0.102213   |     -      |     -     |   15.67  \n","   2    |  2440   |   0.100806   |     -      |     -     |   15.71  \n","   2    |  2460   |   0.062018   |     -      |     -     |   15.69  \n","   2    |  2480   |   0.083558   |     -      |     -     |   15.68  \n","   2    |  2500   |   0.105860   |     -      |     -     |   15.68  \n","   2    |  2520   |   0.160053   |     -      |     -     |   15.68  \n","   2    |  2540   |   0.132685   |     -      |     -     |   15.67  \n","   2    |  2560   |   0.075723   |     -      |     -     |   15.67  \n","   2    |  2580   |   0.094840   |     -      |     -     |   15.70  \n","   2    |  2600   |   0.112346   |     -      |     -     |   15.68  \n","   2    |  2620   |   0.073532   |     -      |     -     |   15.68  \n","   2    |  2640   |   0.077393   |     -      |     -     |   15.68  \n","   2    |  2660   |   0.091316   |     -      |     -     |   15.66  \n","   2    |  2680   |   0.111902   |     -      |     -     |   15.66  \n","   2    |  2700   |   0.080386   |     -      |     -     |   15.66  \n","   2    |  2720   |   0.071053   |     -      |     -     |   15.67  \n","   2    |  2740   |   0.100132   |     -      |     -     |   15.67  \n","   2    |  2760   |   0.089828   |     -      |     -     |   15.67  \n","   2    |  2780   |   0.094883   |     -      |     -     |   15.68  \n","   2    |  2800   |   0.126506   |     -      |     -     |   15.68  \n","   2    |  2820   |   0.116546   |     -      |     -     |   15.66  \n","   2    |  2840   |   0.121248   |     -      |     -     |   15.68  \n","   2    |  2860   |   0.074864   |     -      |     -     |   15.67  \n","   2    |  2880   |   0.110924   |     -      |     -     |   15.68  \n","   2    |  2900   |   0.055128   |     -      |     -     |   15.67  \n","   2    |  2920   |   0.150726   |     -      |     -     |   15.66  \n","   2    |  2940   |   0.116989   |     -      |     -     |   15.68  \n","   2    |  2960   |   0.142785   |     -      |     -     |   15.68  \n","   2    |  2980   |   0.186355   |     -      |     -     |   15.67  \n","   2    |  3000   |   0.053002   |     -      |     -     |   15.68  \n","   2    |  3020   |   0.164603   |     -      |     -     |   15.67  \n","   2    |  3040   |   0.095207   |     -      |     -     |   15.66  \n","   2    |  3060   |   0.126409   |     -      |     -     |   15.66  \n","   2    |  3080   |   0.070748   |     -      |     -     |   15.68  \n","   2    |  3100   |   0.082281   |     -      |     -     |   15.68  \n","   2    |  3120   |   0.101725   |     -      |     -     |   15.67  \n","   2    |  3140   |   0.136012   |     -      |     -     |   15.66  \n","   2    |  3160   |   0.126598   |     -      |     -     |   15.68  \n","   2    |  3180   |   0.153174   |     -      |     -     |   15.66  \n","   2    |  3200   |   0.137609   |     -      |     -     |   15.66  \n","   2    |  3220   |   0.131822   |     -      |     -     |   15.69  \n","   2    |  3240   |   0.125484   |     -      |     -     |   15.69  \n","   2    |  3260   |   0.088941   |     -      |     -     |   15.67  \n","   2    |  3280   |   0.089508   |     -      |     -     |   15.69  \n","   2    |  3300   |   0.087868   |     -      |     -     |   15.65  \n","   2    |  3320   |   0.071224   |     -      |     -     |   15.70  \n","   2    |  3340   |   0.095250   |     -      |     -     |   15.66  \n","   2    |  3360   |   0.158229   |     -      |     -     |   15.69  \n","   2    |  3380   |   0.066355   |     -      |     -     |   15.66  \n","   2    |  3400   |   0.105258   |     -      |     -     |   15.66  \n","   2    |  3420   |   0.076753   |     -      |     -     |   15.68  \n","   2    |  3440   |   0.191948   |     -      |     -     |   15.71  \n","   2    |  3460   |   0.091722   |     -      |     -     |   15.67  \n","   2    |  3480   |   0.054906   |     -      |     -     |   15.69  \n","   2    |  3500   |   0.128426   |     -      |     -     |   15.66  \n","   2    |  3520   |   0.129624   |     -      |     -     |   15.71  \n","   2    |  3540   |   0.100211   |     -      |     -     |   15.66  \n","   2    |  3560   |   0.181520   |     -      |     -     |   15.70  \n","   2    |  3580   |   0.124967   |     -      |     -     |   15.68  \n","   2    |  3600   |   0.120356   |     -      |     -     |   15.68  \n","   2    |  3620   |   0.029178   |     -      |     -     |   15.67  \n","   2    |  3640   |   0.144280   |     -      |     -     |   15.68  \n","   2    |  3660   |   0.047136   |     -      |     -     |   15.65  \n","   2    |  3680   |   0.085502   |     -      |     -     |   15.66  \n","   2    |  3700   |   0.126208   |     -      |     -     |   15.69  \n","   2    |  3720   |   0.099587   |     -      |     -     |   15.66  \n","   2    |  3740   |   0.085462   |     -      |     -     |   15.61  \n","   2    |  3760   |   0.091522   |     -      |     -     |   15.62  \n","   2    |  3780   |   0.098376   |     -      |     -     |   15.64  \n","   2    |  3800   |   0.139252   |     -      |     -     |   15.67  \n","   2    |  3820   |   0.092769   |     -      |     -     |   15.67  \n","   2    |  3840   |   0.106046   |     -      |     -     |   15.67  \n","   2    |  3860   |   0.084312   |     -      |     -     |   15.70  \n","   2    |  3880   |   0.133267   |     -      |     -     |   15.69  \n","   2    |  3900   |   0.087326   |     -      |     -     |   15.69  \n","   2    |  3920   |   0.095383   |     -      |     -     |   15.70  \n","   2    |  3940   |   0.160961   |     -      |     -     |   15.68  \n","   2    |  3950   |   0.140122   |     -      |     -     |   7.84   \n","----------------------------------------------------------------------\n","   2    |    -    |   0.113621   |  0.167432  |   95.61   |  3222.61 \n","----------------------------------------------------------------------\n","\n","\n","Training complete!\n"]}],"source":["set_seed(42) \n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"Pi0d0Im5QxvH","executionInfo":{"status":"ok","timestamp":1644057846673,"user_tz":-330,"elapsed":1468,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"}}},"outputs":[],"source":["import pickle\n","filename = 'trained-distilbert-base-uncased-emotion-BiLSTM.sav'\n","pickle.dump(bert_classifier, open(filename, 'wb'))"]},{"cell_type":"code","source":["# # Loading the model (to avoid retraining in reruns)\n","\n","# import pickle\n","# filename = 'trained-distilbert-base-uncased-emotion-BiLSTM.sav'\n","# f = open(filename, 'rb')\n","# bert_classifier = pickle.load(f)"],"metadata":{"id":"9H2-KF9-vstI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":1165,"status":"ok","timestamp":1644060957905,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"Y84FNM8rlMuq"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def bert_predict(model, test_dataloader):\n","    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n","    on the test set.\n","    \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    all_logits = []\n","\n","    # For each batch in our test set...\n","    for batch in test_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","        all_logits.append(logits)\n","    \n","    # Concatenate logits from each batch\n","    all_logits = torch.cat(all_logits, dim=0)\n","\n","    # Apply softmax to calculate probabilities\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","\n","    return probs"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":542,"status":"ok","timestamp":1644060978243,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"BaP0b0jclMxY"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, roc_curve, auc, precision_score, recall_score\n","from sklearn.metrics import precision_recall_curve, f1_score\n","\n","def evaluate_roc(probs, y_true):\n","    \"\"\"\n","    - Print AUC and accuracy on the test set\n","    - Plot ROC\n","    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n","    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n","    \"\"\"\n","    preds = probs[:, 1]\n","    fpr, tpr, threshold = roc_curve(y_true, preds)\n","    roc_auc = auc(fpr, tpr)\n","    print(f'AUC: {roc_auc:.4f}')\n","       \n","    # Get accuracy over the test set\n","    y_pred = np.where(preds >= 0.5, 1, 0)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(f'Accuracy: {accuracy*100:.2f}%')\n","\n","    #Get Precision and Recall over the test set\n","    precision  = precision_score(y_true, y_pred, average='binary')\n","    print(f'Precision: {precision*100:.2f}%')\n","    recall = recall_score(y_true, y_pred, average='binary')\n","    print(f'Recall: {recall*100:.2f}%')\n","\n","    f1 = f1_score(y_true, y_pred)\n","\n","    \n","    # Plot ROC AUC\n","    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","    plt.legend(loc = 'lower right')\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.show()\n","\n","    print('DistilbertBase-BiLSTM: f1=%.3f ' % (f1))\n","    # plot the precision-recall curves\n","    baseline = len(y_test[y_test==1]) / len(y_test)\n","    plt.plot([0, 1], [baseline, baseline], linestyle='--', label='Baseline')\n","    plt.plot(recall, precision, marker='.', label='DistilbertBase-BiLSTM')\n","    # axis labels\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    # show the legend\n","    plt.legend()\n","    # show the plot\n","    plt.show()\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":632},"executionInfo":{"elapsed":127535,"status":"ok","timestamp":1644061107895,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"MUH-ejXRlMz9","outputId":"566fbe20-54b0-40bd-c454-2b52b21f79c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["AUC: 0.9909\n","Accuracy: 95.60%\n","Precision: 95.59%\n","Recall: 96.37%\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["DistilbertBase-BiLSTM: f1=0.960 \n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# Compute predicted probabilities on the validation set\n","probs = bert_predict(bert_classifier, val_dataloader)\n","\n","# Evaluate the Bert classifier\n","evaluate_roc(probs, y_val)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8010,"status":"ok","timestamp":1644061115799,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"Yvvheq0qlM3d","outputId":"0a711616-4b31-467c-dc2a-f2a5ba65af0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing data...\n"]}],"source":["# Run `preprocessing_for_bert` on the test set\n","print('Tokenizing data...')\n","test_inputs, test_masks = preprocessing_for_bert(X_test)\n","\n","# Create the DataLoader for our test set\n","test_dataset = TensorDataset(test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313676,"status":"ok","timestamp":1644061429450,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"ENShAjsVlh0P","outputId":"1f2df3d4-4776-43fe-d8eb-2bd9f7260629"},"outputs":[{"output_type":"stream","name":"stdout","text":["no-negative tweets ratio  0.558567279767667\n"]}],"source":["# Compute predicted probabilities on the test set\n","probs = bert_predict(bert_classifier, test_dataloader)\n","\n","# Get predictions from the probabilities\n","threshold = 0.5\n","preds = np.where(probs[:, 1] > threshold, 1, 0)\n","\n","# Number of tweets predicted non-negative\n","print(\"no-negative tweets ratio \", preds.sum()/len(preds))"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":632},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1644061429451,"user":{"displayName":"Yash Sharma","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04578811976861982751"},"user_tz":-330},"id":"4nMBgpwvlh3D","outputId":"04621cd1-bdc5-4432-9c15-94ee38887268"},"outputs":[{"output_type":"stream","name":"stdout","text":["AUC: 0.9909\n","Accuracy: 95.64%\n","Precision: 95.82%\n","Recall: 96.35%\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["DistilbertBase-BiLSTM: f1=0.961 \n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# Evaluate the Bert classifier for unseen test data\n","evaluate_roc(probs, y_test)"]},{"cell_type":"markdown","source":["Dataset 1"],"metadata":{"id":"W7eLOG2uuw_x"}},{"cell_type":"code","source":["X = df1.text.values\n","y = df1.sentiment.values\n","X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"],"metadata":{"id":"blHSYaz9rWGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify `MAX_LEN`\n","MAX_LEN =  280\n","\n","# Print sentence 0 and its encoded token ids\n","token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n","print('Original: ', X[0])\n","print('Token IDs: ', token_ids)\n","\n","# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n","val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"],"metadata":{"id":"LHkD3v3DrWJc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 16\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"metadata":{"id":"PFgGW0g7rWMk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(42) \n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"],"metadata":{"id":"C15aScZ7rWQI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, val_dataloader)\n","\n","# Evaluate the Bert classifier\n","evaluate_roc(probs, y_val)"],"metadata":{"id":"BV8qdxdorWW3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Tokenizing data...')\n","test_inputs, test_masks = preprocessing_for_bert(X_test)\n","\n","# Create the DataLoader for our test set\n","test_dataset = TensorDataset(test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"],"metadata":{"id":"IWA5L_vXrWZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, test_dataloader)\n","\n","# Get predictions from the probabilities\n","threshold = 0.5\n","preds = np.where(probs[:, 1] > threshold, 1, 0)\n","\n","# Number of tweets predicted non-negative\n","print(\"no-negative tweets ratio \", preds.sum()/len(preds))"],"metadata":{"id":"vmU48X_wrWcA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the Bert classifier for unseen test data\n","evaluate_roc(probs, y_test)"],"metadata":{"id":"q2J_5WbYrWe3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset 2"],"metadata":{"id":"__XHLDr7sXzY"}},{"cell_type":"code","source":["X = df2.text.values\n","y = df2.sentiment.values\n","X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"],"metadata":{"id":"KL4fvGwtsfMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify `MAX_LEN`\n","MAX_LEN =  280\n","\n","# Print sentence 0 and its encoded token ids\n","token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n","print('Original: ', X[0])\n","print('Token IDs: ', token_ids)\n","\n","# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n","val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"],"metadata":{"id":"UWZaHaRHsfMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 16\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"metadata":{"id":"E9HVAST2sfMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(42) \n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"],"metadata":{"id":"0DgNVgLYstSd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, val_dataloader)\n","\n","# Evaluate the Bert classifier\n","evaluate_roc(probs, y_val)"],"metadata":{"id":"wsQvAkT3stSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Tokenizing data...')\n","test_inputs, test_masks = preprocessing_for_bert(X_test)\n","\n","# Create the DataLoader for our test set\n","test_dataset = TensorDataset(test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"],"metadata":{"id":"Rfb1hZkNstSf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, test_dataloader)\n","\n","# Get predictions from the probabilities\n","threshold = 0.5\n","preds = np.where(probs[:, 1] > threshold, 1, 0)\n","\n","# Number of tweets predicted non-negative\n","print(\"no-negative tweets ratio \", preds.sum()/len(preds))"],"metadata":{"id":"k9kl_X-NstSf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the Bert classifier for unseen test data\n","evaluate_roc(probs, y_test)"],"metadata":{"id":"CIYUYUDxstSg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"uCx1zoZpsihF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset 3"],"metadata":{"id":"9P3Sl4TyskJ_"}},{"cell_type":"code","source":["X = df3.text.values\n","y = df3.sentiment.values\n","X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"],"metadata":{"id":"NJaYb6qVsmgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify `MAX_LEN`\n","MAX_LEN =  280\n","\n","# Print sentence 0 and its encoded token ids\n","token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n","print('Original: ', X[0])\n","print('Token IDs: ', token_ids)\n","\n","# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n","val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"],"metadata":{"id":"cDP6Aq1lsmgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 16\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"metadata":{"id":"mGH5uKTBsmgq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(42) \n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"],"metadata":{"id":"Ohu1X0l4sv_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, val_dataloader)\n","\n","# Evaluate the Bert classifier\n","evaluate_roc(probs, y_val)"],"metadata":{"id":"ehKs_Hoasv_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Tokenizing data...')\n","test_inputs, test_masks = preprocessing_for_bert(X_test)\n","\n","# Create the DataLoader for our test set\n","test_dataset = TensorDataset(test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"],"metadata":{"id":"zWWGeZrEsv_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, test_dataloader)\n","\n","# Get predictions from the probabilities\n","threshold = 0.5\n","preds = np.where(probs[:, 1] > threshold, 1, 0)\n","\n","# Number of tweets predicted non-negative\n","print(\"no-negative tweets ratio \", preds.sum()/len(preds))"],"metadata":{"id":"NnilNQbIsv_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the Bert classifier for unseen test data\n","evaluate_roc(probs, y_test)"],"metadata":{"id":"MkPnUPx3sv_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"mLr3anZ4siof"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset 4"],"metadata":{"id":"EaM6piRas1XO"}},{"cell_type":"code","source":["X = df4.text.values\n","y = df4.sentiment.values\n","X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"],"metadata":{"id":"RbrKWSI3s91p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify `MAX_LEN`\n","MAX_LEN =  280\n","\n","# Print sentence 0 and its encoded token ids\n","token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n","print('Original: ', X[0])\n","print('Token IDs: ', token_ids)\n","\n","# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n","val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"],"metadata":{"id":"fxx7ZTm1s91q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 16\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"metadata":{"id":"T_vwMKHbs91r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(42) \n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"],"metadata":{"id":"sCo5YrVZs2jU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, val_dataloader)\n","\n","# Evaluate the Bert classifier\n","evaluate_roc(probs, y_val)"],"metadata":{"id":"HUp-hx4vs2jV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Tokenizing data...')\n","test_inputs, test_masks = preprocessing_for_bert(X_test)\n","\n","# Create the DataLoader for our test set\n","test_dataset = TensorDataset(test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"],"metadata":{"id":"D8_J4ZsEs2jV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, test_dataloader)\n","\n","# Get predictions from the probabilities\n","threshold = 0.5\n","preds = np.where(probs[:, 1] > threshold, 1, 0)\n","\n","# Number of tweets predicted non-negative\n","print(\"no-negative tweets ratio \", preds.sum()/len(preds))"],"metadata":{"id":"rSoWoSPZs2jW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the Bert classifier for unseen test data\n","evaluate_roc(probs, y_test)"],"metadata":{"id":"qSqZKD1vs2jW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"QFJkGQigsits"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset 5"],"metadata":{"id":"niWG8neUs4No"}},{"cell_type":"code","source":["X = df5.text.values\n","y = df5.sentiment.values\n","X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n","X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"],"metadata":{"id":"SQV4jrVms_90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify `MAX_LEN`\n","MAX_LEN =  280\n","\n","# Print sentence 0 and its encoded token ids\n","token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n","print('Original: ', X[0])\n","print('Token IDs: ', token_ids)\n","\n","# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n","val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"],"metadata":{"id":"unFyjf8os_91"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 16\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"metadata":{"id":"OBSt28hOs_92"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(42) \n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"],"metadata":{"id":"CyEj0m9ms56o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, val_dataloader)\n","\n","# Evaluate the Bert classifier\n","evaluate_roc(probs, y_val)"],"metadata":{"id":"FJz8jcOQs56p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Tokenizing data...')\n","test_inputs, test_masks = preprocessing_for_bert(X_test)\n","\n","# Create the DataLoader for our test set\n","test_dataset = TensorDataset(test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"],"metadata":{"id":"hx1c_2xbs56q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = bert_predict(bert_classifier, test_dataloader)\n","\n","# Get predictions from the probabilities\n","threshold = 0.5\n","preds = np.where(probs[:, 1] > threshold, 1, 0)\n","\n","# Number of tweets predicted non-negative\n","print(\"no-negative tweets ratio \", preds.sum()/len(preds))"],"metadata":{"id":"2dz6at6Ys56q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the Bert classifier for unseen test data\n","evaluate_roc(probs, y_test)"],"metadata":{"id":"UGl5A0X0s56q"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Distilbert-BiLSTM.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"71c2961396874a4296d1b4de7e15f250":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f78c2825bac048cd950824eedf71824f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_adff7bf391134c49bc5af8ed7a07092d","IPY_MODEL_cfa07037637647afae8ce46993aca7e2","IPY_MODEL_44e7d035409543fea94faac7579bf944"]}},"f78c2825bac048cd950824eedf71824f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"adff7bf391134c49bc5af8ed7a07092d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c22ee813fac64756ad5670fc157e92c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_693a83155c05429ea70db61040a58903"}},"cfa07037637647afae8ce46993aca7e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_865e92058ee542aaa56bbe507c85f831","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":291,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":291,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_baa013b5198643faa2faa554eb3ad3d7"}},"44e7d035409543fea94faac7579bf944":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db48f02c469049da8e0a46e446f58506","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 291/291 [00:00&lt;00:00, 4.36kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_70b126751bde476eb3e2e2447467d390"}},"c22ee813fac64756ad5670fc157e92c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"693a83155c05429ea70db61040a58903":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"865e92058ee542aaa56bbe507c85f831":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"baa013b5198643faa2faa554eb3ad3d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db48f02c469049da8e0a46e446f58506":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"70b126751bde476eb3e2e2447467d390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a0f4e92c0cd4123b59f8a1f87a1e5da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_96813cd0c45542f5b4afe937e1a31a0e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8027d770e628447da3a5960c8311ae36","IPY_MODEL_94247be1e65d4618963bcd128caab47c","IPY_MODEL_081d6b3f235346c39250d191787f077b"]}},"96813cd0c45542f5b4afe937e1a31a0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8027d770e628447da3a5960c8311ae36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_05dc92ff0a874c74874fa90683f29ccc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b5a79320595b4758a3bb1ce7fc9a6339"}},"94247be1e65d4618963bcd128caab47c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2508efa658dc4f24a6ba4486464d60a4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":768,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":768,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef917737d907401588cbc8e396cfcb46"}},"081d6b3f235346c39250d191787f077b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_630f95f1e6104c7d9206c26be8d20007","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 768/768 [00:00&lt;00:00, 19.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b14daf1a34a4816b4b57ac88f68ee7c"}},"05dc92ff0a874c74874fa90683f29ccc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b5a79320595b4758a3bb1ce7fc9a6339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2508efa658dc4f24a6ba4486464d60a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ef917737d907401588cbc8e396cfcb46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"630f95f1e6104c7d9206c26be8d20007":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0b14daf1a34a4816b4b57ac88f68ee7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"169b426e31204bfc898e66554505fa85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2e41096f62f9421bb9b4b2a6fba2d5c4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5809b462ca70442b8809a9a88adc58a9","IPY_MODEL_37b2a0386ea140dd9132bd87603c5da4","IPY_MODEL_ecfbb650bd834d3798bae228526c303e"]}},"2e41096f62f9421bb9b4b2a6fba2d5c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5809b462ca70442b8809a9a88adc58a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e8fb9d418f5e439ea0324820e1e0dfed","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10b31874aca54be3b20c70b093305ffa"}},"37b2a0386ea140dd9132bd87603c5da4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_51543c0dceff4ae5b1f3017e040fccd5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_379ff5ccdbd048a4894fd5c039564fa6"}},"ecfbb650bd834d3798bae228526c303e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_400c09fbfb314b3280fbb7c94da6a948","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 1.06MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be059c65f77541d3b0b727673ef902a9"}},"e8fb9d418f5e439ea0324820e1e0dfed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"10b31874aca54be3b20c70b093305ffa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51543c0dceff4ae5b1f3017e040fccd5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"379ff5ccdbd048a4894fd5c039564fa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"400c09fbfb314b3280fbb7c94da6a948":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"be059c65f77541d3b0b727673ef902a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5ed451092334bfeaa580ad2643143d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_33dac5ea76134613b34d9c950539ad8f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee04d865572142988416c855d6737c5a","IPY_MODEL_aca390e6630f4a81bfa4a20016823bd2","IPY_MODEL_7a824931c883424ea13d0e1ad8f6f2ea"]}},"33dac5ea76134613b34d9c950539ad8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee04d865572142988416c855d6737c5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3db3dfe2405a4742994073a77eee0751","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_608fe6a7a3c4425fabca53ada98f2eff"}},"aca390e6630f4a81bfa4a20016823bd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c8aabe8055214bf8bad9596872950f7f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56692ad6b00d44a7b621f809d592eed8"}},"7a824931c883424ea13d0e1ad8f6f2ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be7d88eebcc34a7f8791557c88f3d96f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 2.79kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_238435899b5d4c6c8818f5fbeb303502"}},"3db3dfe2405a4742994073a77eee0751":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"608fe6a7a3c4425fabca53ada98f2eff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8aabe8055214bf8bad9596872950f7f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"56692ad6b00d44a7b621f809d592eed8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be7d88eebcc34a7f8791557c88f3d96f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"238435899b5d4c6c8818f5fbeb303502":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39634959f860454196b892cf99966c56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6f2092e24eb54ceb902020c1f9c3e464","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8d8a0280949e41c3abda066c85bbde1b","IPY_MODEL_b567b18b9b0e40e1bcb775617b425c78","IPY_MODEL_94350f53691b4c53b08292e659ad0151"]}},"6f2092e24eb54ceb902020c1f9c3e464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d8a0280949e41c3abda066c85bbde1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3aafedaab5f84566919fe77c04c531ad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a65d770e0e24be186f77eab8a470826"}},"b567b18b9b0e40e1bcb775617b425c78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_09aa4986e7f14f44a37471e72ae21b8e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":267875479,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":267875479,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e472aaab4af4ae88b8632ea23d91270"}},"94350f53691b4c53b08292e659ad0151":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0c7ddfba658843619d43c8ccfb8a49ed","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"‚Äã","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 255M/255M [00:21&lt;00:00, 7.65MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cbc10230dcd943e8ab88146d89116fb9"}},"3aafedaab5f84566919fe77c04c531ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7a65d770e0e24be186f77eab8a470826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"09aa4986e7f14f44a37471e72ae21b8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9e472aaab4af4ae88b8632ea23d91270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c7ddfba658843619d43c8ccfb8a49ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cbc10230dcd943e8ab88146d89116fb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}