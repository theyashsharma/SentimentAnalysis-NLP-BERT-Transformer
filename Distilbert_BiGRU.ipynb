{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distilbert-BiGRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16ef4a53fa8944259f7c4cf332c7976f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3032f19af9fb4cf7aee5a84c2a8c9254",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1269715970a4ba89ff373cb3c2faeed",
              "IPY_MODEL_84a64308d8a6454bbcd87f6bdb0d987e",
              "IPY_MODEL_f32ee4e2e233430e8fa0993bc1b318b1"
            ]
          }
        },
        "3032f19af9fb4cf7aee5a84c2a8c9254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1269715970a4ba89ff373cb3c2faeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac36686db36847519f63f6dda0b6601e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6437f1bbcacb43dc990ceaf4c603e46e"
          }
        },
        "84a64308d8a6454bbcd87f6bdb0d987e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_520d7e40e14944dd8b4dae75a5e85849",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 291,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 291,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d818c66d0c44d2282b0080393ff85b6"
          }
        },
        "f32ee4e2e233430e8fa0993bc1b318b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81a55fad9e10495abde7735a25bc4ddf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 291/291 [00:00&lt;00:00, 8.73kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c06eaa04b4b8403dad5ce0f56d496f4e"
          }
        },
        "ac36686db36847519f63f6dda0b6601e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6437f1bbcacb43dc990ceaf4c603e46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "520d7e40e14944dd8b4dae75a5e85849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d818c66d0c44d2282b0080393ff85b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81a55fad9e10495abde7735a25bc4ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c06eaa04b4b8403dad5ce0f56d496f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b51719c4f9594caa92dbb5ac09547a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d5c9004499a4562983d2f363d675ad2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9e6c3bc76bb4e3aadc6c408d3eb46eb",
              "IPY_MODEL_82711bbfb48242998ea7b9ca6138d040",
              "IPY_MODEL_c8e19d82dce84eecbecc1eb7f3800b37"
            ]
          }
        },
        "4d5c9004499a4562983d2f363d675ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9e6c3bc76bb4e3aadc6c408d3eb46eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4f703e182d547f7a0cfdf5b6d6b18d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62aa16afc4c742478356606c6e351a59"
          }
        },
        "82711bbfb48242998ea7b9ca6138d040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb8c5630abb04afebb42fb51d4289da7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 768,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 768,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53c81ba6265a4fce8c9f2d2243fd202b"
          }
        },
        "c8e19d82dce84eecbecc1eb7f3800b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0181efae566844648673c5c3aac82018",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 768/768 [00:00&lt;00:00, 22.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55c2cb12a7ba4a69a271340e6449815d"
          }
        },
        "b4f703e182d547f7a0cfdf5b6d6b18d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62aa16afc4c742478356606c6e351a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb8c5630abb04afebb42fb51d4289da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53c81ba6265a4fce8c9f2d2243fd202b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0181efae566844648673c5c3aac82018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55c2cb12a7ba4a69a271340e6449815d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a0113d2040a406a8e74d6f0fd2342ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_22802d0a604f488e9d639fcff5ef107c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4e55c753b8a54c459dcfa40c5d3ee705",
              "IPY_MODEL_fce461bc693840c98d523752abc4bb88",
              "IPY_MODEL_0405221f6e3041fa8dd9386ad34e7d86"
            ]
          }
        },
        "22802d0a604f488e9d639fcff5ef107c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e55c753b8a54c459dcfa40c5d3ee705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3fe5587e26094ea38ab2bbba42f9880e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0dfdb9ee0667449f894d062a0530966b"
          }
        },
        "fce461bc693840c98d523752abc4bb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a69d7c3a49704264bd0cdfa07fd9d11b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e80e2c7694441589a3f339c236cb4fd"
          }
        },
        "0405221f6e3041fa8dd9386ad34e7d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2968d5158565455aa78106fc91d22cb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 1.14MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_711ed12e90054f7fa265988e5b243bf4"
          }
        },
        "3fe5587e26094ea38ab2bbba42f9880e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0dfdb9ee0667449f894d062a0530966b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a69d7c3a49704264bd0cdfa07fd9d11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e80e2c7694441589a3f339c236cb4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2968d5158565455aa78106fc91d22cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "711ed12e90054f7fa265988e5b243bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0d0261add4a4b799786c397d020937b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71129fdb64884229a31c80404b45400a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5704f16066d8486db1f046ab4aa0cf7e",
              "IPY_MODEL_bee6fb901e164cf7929cc88e50d65346",
              "IPY_MODEL_1afa869cea7e4582b2560692802a3213"
            ]
          }
        },
        "71129fdb64884229a31c80404b45400a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5704f16066d8486db1f046ab4aa0cf7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bfdcb5a101f4160b708ea00d0325295",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_833db475d52649c09b2dd3b3e8225fec"
          }
        },
        "bee6fb901e164cf7929cc88e50d65346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_328a537dd8de45d3b2e842c04f9fe622",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f117abe0cb846bc98c244206a810e7a"
          }
        },
        "1afa869cea7e4582b2560692802a3213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2be9ac21926544fcad824602a13dca2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 3.23kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e60b01fcc46a4b9ab55743563b2320c1"
          }
        },
        "7bfdcb5a101f4160b708ea00d0325295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "833db475d52649c09b2dd3b3e8225fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "328a537dd8de45d3b2e842c04f9fe622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f117abe0cb846bc98c244206a810e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2be9ac21926544fcad824602a13dca2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e60b01fcc46a4b9ab55743563b2320c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fc45beb27a54daabe53384e2f300cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0fbc4f8500e44364bd6e0b41b5b1cc59",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa0bbb4509d84c1bb7bd2e3717106c59",
              "IPY_MODEL_3ce9d996545746ccbb3cc5c25718833b",
              "IPY_MODEL_ed181a7068534844a5cc99ba7c3cad93"
            ]
          }
        },
        "0fbc4f8500e44364bd6e0b41b5b1cc59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa0bbb4509d84c1bb7bd2e3717106c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68e8db13cf174f8e8fdd3a9ee91b2968",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ac8f63fb4c043c68ff38f82023682f6"
          }
        },
        "3ce9d996545746ccbb3cc5c25718833b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51389767ab2a4af58b26d7ce9a8d5943",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267875479,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267875479,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f113ff145b843399d8c569238537ea5"
          }
        },
        "ed181a7068534844a5cc99ba7c3cad93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0cec2f4ad61f4410b102a1095e0e5a11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 255M/255M [00:15&lt;00:00, 11.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63ddce57a5d34776a8b7e7ca74598bce"
          }
        },
        "68e8db13cf174f8e8fdd3a9ee91b2968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ac8f63fb4c043c68ff38f82023682f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51389767ab2a4af58b26d7ce9a8d5943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f113ff145b843399d8c569238537ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cec2f4ad61f4410b102a1095e0e5a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63ddce57a5d34776a8b7e7ca74598bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment classification with English Twitter Datasets"
      ],
      "metadata": {
        "id": "05KYS_pnO3Dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "8_6lr4dbPZNZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O2ganP7WOcv-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 ) Loading Datasets"
      ],
      "metadata": {
        "id": "IpJdkXmSPKfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('tweets_sqgames.csv')\n",
        "df1 = df1.loc[:, ['text', 'sentiment']]\n",
        "label_mapping = {\"Positive\": 1, \"Negative\":0}\n",
        "df1 = df1[df1.sentiment != \"Neutral\"]\n",
        "df1[\"sentiment\"] = df1[\"sentiment\"].map(label_mapping)"
      ],
      "metadata": {
        "id": "E200bW4uv0hW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('Tweets.csv')\n",
        "df2 = df2.loc[:, ['text', 'airline_sentiment']]\n",
        "df2 = df2.rename(columns = {\"airline_sentiment\":\"sentiment\"})\n",
        "label_mapping = {\"positive\": 1, \"negative\":0}\n",
        "df2 = df2[df2.sentiment != \"neutral\"]\n",
        "df2[\"sentiment\"] = df2[\"sentiment\"].map(label_mapping)"
      ],
      "metadata": {
        "id": "9zdyPvyDv0kq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.read_csv('apple-twitter-sentiment-texts.csv')\n",
        "label_mapping = {1: 1, -1:0}\n",
        "df3 = df3[df3.sentiment != 0]\n",
        "df3[\"sentiment\"] = df3[\"sentiment\"].map(label_mapping)"
      ],
      "metadata": {
        "id": "wKAkAPNlv0r6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.read_csv('Apple-Twitter-Sentiment-DFE.csv', encoding=\"Latin-1\")\n",
        "label_mapping = {\"5\": 1, \"1\":0}\n",
        "df4 = df4[df4.sentiment != \"3\"]\n",
        "df4 = df4[df4.sentiment != \"not_relevant\"]\n",
        "df4[\"sentiment\"] = df4[\"sentiment\"].map(label_mapping)"
      ],
      "metadata": {
        "id": "f-d6W4F4v0vR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = pd.read_csv('Reddit_Data.csv')\n",
        "df5 = df5.rename(columns = {\"clean_comment\":\"text\", \"category\":\"sentiment\"})\n",
        "label_mapping = {1: 1, -1:0}\n",
        "df5 = df5[df5.sentiment != 0]\n",
        "df5[\"sentiment\"] = df5[\"sentiment\"].map(label_mapping)"
      ],
      "metadata": {
        "id": "77x4gFaC6Dry"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [df1, df2, df3, df4, df5]\n",
        "merged_df = pd.concat(frames)"
      ],
      "metadata": {
        "id": "cb3WdLmXId77"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = merged_df.text.values\n",
        "y = merged_df.sentiment.values"
      ],
      "metadata": {
        "id": "M0LtDH9_O1pm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "5H2DVOPHO1sE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 ) Deep Learning Approach"
      ],
      "metadata": {
        "id": "HakjkIbYY-EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oBZeFVSO2AH",
        "outputId": "013a9129-f95b-4a03-dec8-ce4ba8f3ae32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI790cijO2GE",
        "outputId": "c787413d-b1f9-45c6-f74d-387b339859fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 36.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 35.0 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "SLMSbnC5O2DJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")"
      ],
      "metadata": {
        "id": "xMmgFGdOO2Jh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "16ef4a53fa8944259f7c4cf332c7976f",
            "3032f19af9fb4cf7aee5a84c2a8c9254",
            "a1269715970a4ba89ff373cb3c2faeed",
            "84a64308d8a6454bbcd87f6bdb0d987e",
            "f32ee4e2e233430e8fa0993bc1b318b1",
            "ac36686db36847519f63f6dda0b6601e",
            "6437f1bbcacb43dc990ceaf4c603e46e",
            "520d7e40e14944dd8b4dae75a5e85849",
            "5d818c66d0c44d2282b0080393ff85b6",
            "81a55fad9e10495abde7735a25bc4ddf",
            "c06eaa04b4b8403dad5ce0f56d496f4e",
            "b51719c4f9594caa92dbb5ac09547a1f",
            "4d5c9004499a4562983d2f363d675ad2",
            "e9e6c3bc76bb4e3aadc6c408d3eb46eb",
            "82711bbfb48242998ea7b9ca6138d040",
            "c8e19d82dce84eecbecc1eb7f3800b37",
            "b4f703e182d547f7a0cfdf5b6d6b18d8",
            "62aa16afc4c742478356606c6e351a59",
            "fb8c5630abb04afebb42fb51d4289da7",
            "53c81ba6265a4fce8c9f2d2243fd202b",
            "0181efae566844648673c5c3aac82018",
            "55c2cb12a7ba4a69a271340e6449815d",
            "5a0113d2040a406a8e74d6f0fd2342ce",
            "22802d0a604f488e9d639fcff5ef107c",
            "4e55c753b8a54c459dcfa40c5d3ee705",
            "fce461bc693840c98d523752abc4bb88",
            "0405221f6e3041fa8dd9386ad34e7d86",
            "3fe5587e26094ea38ab2bbba42f9880e",
            "0dfdb9ee0667449f894d062a0530966b",
            "a69d7c3a49704264bd0cdfa07fd9d11b",
            "1e80e2c7694441589a3f339c236cb4fd",
            "2968d5158565455aa78106fc91d22cb3",
            "711ed12e90054f7fa265988e5b243bf4",
            "f0d0261add4a4b799786c397d020937b",
            "71129fdb64884229a31c80404b45400a",
            "5704f16066d8486db1f046ab4aa0cf7e",
            "bee6fb901e164cf7929cc88e50d65346",
            "1afa869cea7e4582b2560692802a3213",
            "7bfdcb5a101f4160b708ea00d0325295",
            "833db475d52649c09b2dd3b3e8225fec",
            "328a537dd8de45d3b2e842c04f9fe622",
            "9f117abe0cb846bc98c244206a810e7a",
            "2be9ac21926544fcad824602a13dca2f",
            "e60b01fcc46a4b9ab55743563b2320c1"
          ]
        },
        "outputId": "126309f2-c494-4e47-d3fe-837857e96abe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16ef4a53fa8944259f7c4cf332c7976f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b51719c4f9594caa92dbb5ac09547a1f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/768 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a0113d2040a406a8e74d6f0fd2342ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0d0261add4a4b799786c397d020937b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "\n",
        "    # Normalize unicode encoding\n",
        "    text = unicodedata.normalize('NFC', text)\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    #Remove URLs\n",
        "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '<URL>', text)\n",
        "\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "o2TenWCGZw7I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emojis(sent):\n",
        "    text =  emoji.demojize(sent)\n",
        "    text= re.sub(r'(:[!_\\-\\w]+:)', '', text)\n",
        "    return text\n",
        "    \n",
        "def text_preprocessing_no_emojis(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "  \n",
        "    # Remove emojis\n",
        "    text = remove_emojis(text)\n",
        "\n",
        "    return text_preprocessing(text)"
      ],
      "metadata": {
        "id": "Lp6sDjV9L2hQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gklJcuwha7hu",
        "outputId": "758269c8-a149-4b91-94a1-42e94636e2f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.3.tar.gz (174 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=79953fe12a689f8ebb1cbec2db74bd5ee182e96913ffd32f708c3f7502fbbe27\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/8b/d7/ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "import unicodedata\n",
        "def preprocessing_for_bert(data, version=\"mini\", text_preprocessing_fn = text_preprocessing):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")# if version == \"mini\" else AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "\n",
        "    # For every sentence...\n",
        "    for i,sent in enumerate(data):\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing_fn(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            padding='max_length',        # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,     # Return attention mask\n",
        "            truncation = True \n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "8fjl5AftaQU7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN =  280\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCm99bITa5hL",
        "outputId": "630795bd-fc01-44f8-ad8c-eddd4569b505"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  When life hits and the same time poverty strikes you\n",
            "Gong Yoo : Lets play a game \n",
            "#SquidGame #Netflix https://t.co/Cx7ifmZ8cN\n",
            "Token IDs:  [101, 2043, 2166, 4978, 1998, 1996, 2168, 2051, 5635, 9326, 2017, 17242, 26823, 1024, 11082, 2377, 1037, 2208, 1001, 26852, 16650, 1001, 20907, 16770, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 1039, 2595, 2581, 10128, 2213, 2480, 2620, 2278, 2078, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenizing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "U7iTT16LbLni"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False, version=\"mini\"):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in = 768\n",
        "        H, D_out = 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = AutoModel.from_pretrained(\"bhadresh-savani/distilbert-base-uncased-emotion\")\n",
        "        self.gru = nn.GRU(768, 256,batch_first = True, bidirectional = True)\n",
        "        self.linear = nn.Linear(512, D_out)\n",
        "        self.activation = nn.ReLU()\n",
        "        \n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs[0]\n",
        "        gru_out, _ = self.gru(last_hidden_state)\n",
        "        activated = self.activation(gru_out[:, -1, :])\n",
        "        logits = self.linear(activated)\n",
        "        return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32gvSQ9pb9Fr",
        "outputId": "a4f56d66-34cd-4566-a81d-df681e712dbf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 27.4 ms, sys: 953 µs, total: 28.3 ms\n",
            "Wall time: 31.9 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from torch.optim import SparseAdam, Adam\n",
        "def initialize_model(epochs=4, version=\"base\"):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False, version=version)\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = torch.optim.AdamW(params=list(bert_classifier.parameters()),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "metadata": {
        "id": "z7RwU_UBPHUh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "       \n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "DwlxCFVUPHXN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42) \n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "id": "I0K_YbfyO1TR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6fc45beb27a54daabe53384e2f300cef",
            "0fbc4f8500e44364bd6e0b41b5b1cc59",
            "fa0bbb4509d84c1bb7bd2e3717106c59",
            "3ce9d996545746ccbb3cc5c25718833b",
            "ed181a7068534844a5cc99ba7c3cad93",
            "68e8db13cf174f8e8fdd3a9ee91b2968",
            "2ac8f63fb4c043c68ff38f82023682f6",
            "51389767ab2a4af58b26d7ce9a8d5943",
            "3f113ff145b843399d8c569238537ea5",
            "0cec2f4ad61f4410b102a1095e0e5a11",
            "63ddce57a5d34776a8b7e7ca74598bce"
          ]
        },
        "outputId": "589e67f5-f6f7-4af4-8b21-5c6a67da4443"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fc45beb27a54daabe53384e2f300cef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion were not used when initializing DistilBertModel: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.625149   |     -      |     -     |   23.03  \n",
            "   1    |   40    |   0.516724   |     -      |     -     |   21.95  \n",
            "   1    |   60    |   0.458587   |     -      |     -     |   21.96  \n",
            "   1    |   80    |   0.429405   |     -      |     -     |   21.91  \n",
            "   1    |   100   |   0.505262   |     -      |     -     |   21.96  \n",
            "   1    |   120   |   0.362520   |     -      |     -     |   21.96  \n",
            "   1    |   140   |   0.381369   |     -      |     -     |   21.98  \n",
            "   1    |   160   |   0.388091   |     -      |     -     |   21.99  \n",
            "   1    |   180   |   0.389338   |     -      |     -     |   22.01  \n",
            "   1    |   200   |   0.339074   |     -      |     -     |   22.05  \n",
            "   1    |   220   |   0.521934   |     -      |     -     |   21.99  \n",
            "   1    |   240   |   0.371182   |     -      |     -     |   21.99  \n",
            "   1    |   260   |   0.380523   |     -      |     -     |   21.99  \n",
            "   1    |   280   |   0.326969   |     -      |     -     |   22.00  \n",
            "   1    |   300   |   0.374894   |     -      |     -     |   22.01  \n",
            "   1    |   320   |   0.337836   |     -      |     -     |   22.03  \n",
            "   1    |   340   |   0.334348   |     -      |     -     |   21.95  \n",
            "   1    |   360   |   0.322710   |     -      |     -     |   21.91  \n",
            "   1    |   380   |   0.328344   |     -      |     -     |   21.91  \n",
            "   1    |   400   |   0.265092   |     -      |     -     |   21.95  \n",
            "   1    |   420   |   0.298354   |     -      |     -     |   21.95  \n",
            "   1    |   440   |   0.298117   |     -      |     -     |   21.94  \n",
            "   1    |   460   |   0.251967   |     -      |     -     |   21.94  \n",
            "   1    |   480   |   0.328103   |     -      |     -     |   21.94  \n",
            "   1    |   500   |   0.316126   |     -      |     -     |   21.95  \n",
            "   1    |   520   |   0.303605   |     -      |     -     |   21.92  \n",
            "   1    |   540   |   0.285569   |     -      |     -     |   21.93  \n",
            "   1    |   560   |   0.285254   |     -      |     -     |   21.95  \n",
            "   1    |   580   |   0.279917   |     -      |     -     |   21.94  \n",
            "   1    |   600   |   0.372960   |     -      |     -     |   21.95  \n",
            "   1    |   620   |   0.344136   |     -      |     -     |   21.96  \n",
            "   1    |   640   |   0.308306   |     -      |     -     |   21.94  \n",
            "   1    |   660   |   0.217739   |     -      |     -     |   21.95  \n",
            "   1    |   680   |   0.291530   |     -      |     -     |   21.93  \n",
            "   1    |   700   |   0.259285   |     -      |     -     |   21.95  \n",
            "   1    |   720   |   0.335766   |     -      |     -     |   21.95  \n",
            "   1    |   740   |   0.324261   |     -      |     -     |   21.95  \n",
            "   1    |   760   |   0.297833   |     -      |     -     |   21.92  \n",
            "   1    |   780   |   0.272899   |     -      |     -     |   21.92  \n",
            "   1    |   800   |   0.314486   |     -      |     -     |   21.91  \n",
            "   1    |   820   |   0.234750   |     -      |     -     |   21.94  \n",
            "   1    |   840   |   0.296431   |     -      |     -     |   21.95  \n",
            "   1    |   860   |   0.293694   |     -      |     -     |   21.93  \n",
            "   1    |   880   |   0.216035   |     -      |     -     |   21.94  \n",
            "   1    |   900   |   0.276281   |     -      |     -     |   21.96  \n",
            "   1    |   920   |   0.272074   |     -      |     -     |   21.91  \n",
            "   1    |   940   |   0.213795   |     -      |     -     |   21.91  \n",
            "   1    |   960   |   0.241241   |     -      |     -     |   21.91  \n",
            "   1    |   980   |   0.193568   |     -      |     -     |   21.95  \n",
            "   1    |  1000   |   0.288248   |     -      |     -     |   21.93  \n",
            "   1    |  1020   |   0.227600   |     -      |     -     |   21.93  \n",
            "   1    |  1040   |   0.273307   |     -      |     -     |   21.91  \n",
            "   1    |  1060   |   0.240656   |     -      |     -     |   21.97  \n",
            "   1    |  1080   |   0.233342   |     -      |     -     |   21.93  \n",
            "   1    |  1100   |   0.324524   |     -      |     -     |   21.94  \n",
            "   1    |  1120   |   0.235806   |     -      |     -     |   21.93  \n",
            "   1    |  1140   |   0.234016   |     -      |     -     |   21.96  \n",
            "   1    |  1160   |   0.268925   |     -      |     -     |   21.95  \n",
            "   1    |  1180   |   0.239320   |     -      |     -     |   21.94  \n",
            "   1    |  1200   |   0.236967   |     -      |     -     |   21.95  \n",
            "   1    |  1220   |   0.172653   |     -      |     -     |   21.98  \n",
            "   1    |  1240   |   0.249806   |     -      |     -     |   21.95  \n",
            "   1    |  1260   |   0.279820   |     -      |     -     |   21.95  \n",
            "   1    |  1280   |   0.216871   |     -      |     -     |   21.94  \n",
            "   1    |  1300   |   0.257927   |     -      |     -     |   21.97  \n",
            "   1    |  1320   |   0.216580   |     -      |     -     |   21.92  \n",
            "   1    |  1340   |   0.221014   |     -      |     -     |   21.92  \n",
            "   1    |  1360   |   0.260307   |     -      |     -     |   21.91  \n",
            "   1    |  1380   |   0.202205   |     -      |     -     |   21.94  \n",
            "   1    |  1400   |   0.283095   |     -      |     -     |   21.93  \n",
            "   1    |  1420   |   0.182541   |     -      |     -     |   21.95  \n",
            "   1    |  1440   |   0.242924   |     -      |     -     |   21.96  \n",
            "   1    |  1460   |   0.207810   |     -      |     -     |   21.94  \n",
            "   1    |  1480   |   0.242099   |     -      |     -     |   21.94  \n",
            "   1    |  1500   |   0.276298   |     -      |     -     |   21.94  \n",
            "   1    |  1520   |   0.182755   |     -      |     -     |   21.93  \n",
            "   1    |  1540   |   0.236180   |     -      |     -     |   21.96  \n",
            "   1    |  1560   |   0.206222   |     -      |     -     |   21.95  \n",
            "   1    |  1580   |   0.230755   |     -      |     -     |   21.96  \n",
            "   1    |  1600   |   0.201857   |     -      |     -     |   21.95  \n",
            "   1    |  1620   |   0.213802   |     -      |     -     |   21.94  \n",
            "   1    |  1640   |   0.229169   |     -      |     -     |   21.90  \n",
            "   1    |  1660   |   0.224630   |     -      |     -     |   21.92  \n",
            "   1    |  1680   |   0.176219   |     -      |     -     |   21.94  \n",
            "   1    |  1700   |   0.220213   |     -      |     -     |   21.97  \n",
            "   1    |  1720   |   0.245255   |     -      |     -     |   21.97  \n",
            "   1    |  1740   |   0.184955   |     -      |     -     |   21.95  \n",
            "   1    |  1760   |   0.206374   |     -      |     -     |   21.94  \n",
            "   1    |  1780   |   0.194161   |     -      |     -     |   21.96  \n",
            "   1    |  1800   |   0.187173   |     -      |     -     |   21.97  \n",
            "   1    |  1820   |   0.170510   |     -      |     -     |   21.96  \n",
            "   1    |  1840   |   0.253219   |     -      |     -     |   21.96  \n",
            "   1    |  1860   |   0.138521   |     -      |     -     |   21.93  \n",
            "   1    |  1880   |   0.202911   |     -      |     -     |   21.97  \n",
            "   1    |  1900   |   0.252202   |     -      |     -     |   21.95  \n",
            "   1    |  1920   |   0.183013   |     -      |     -     |   21.95  \n",
            "   1    |  1940   |   0.248385   |     -      |     -     |   21.95  \n",
            "   1    |  1960   |   0.161640   |     -      |     -     |   21.97  \n",
            "   1    |  1980   |   0.243119   |     -      |     -     |   21.95  \n",
            "   1    |  2000   |   0.197211   |     -      |     -     |   21.95  \n",
            "   1    |  2020   |   0.147600   |     -      |     -     |   21.94  \n",
            "   1    |  2040   |   0.204499   |     -      |     -     |   21.96  \n",
            "   1    |  2060   |   0.143102   |     -      |     -     |   21.94  \n",
            "   1    |  2080   |   0.220052   |     -      |     -     |   21.95  \n",
            "   1    |  2100   |   0.219780   |     -      |     -     |   21.96  \n",
            "   1    |  2120   |   0.303706   |     -      |     -     |   21.96  \n",
            "   1    |  2140   |   0.204140   |     -      |     -     |   21.96  \n",
            "   1    |  2160   |   0.172916   |     -      |     -     |   21.95  \n",
            "   1    |  2180   |   0.189181   |     -      |     -     |   21.95  \n",
            "   1    |  2200   |   0.196620   |     -      |     -     |   21.97  \n",
            "   1    |  2220   |   0.240348   |     -      |     -     |   21.95  \n",
            "   1    |  2240   |   0.196148   |     -      |     -     |   21.94  \n",
            "   1    |  2260   |   0.278630   |     -      |     -     |   21.95  \n",
            "   1    |  2280   |   0.171345   |     -      |     -     |   21.96  \n",
            "   1    |  2300   |   0.266736   |     -      |     -     |   21.94  \n",
            "   1    |  2320   |   0.184812   |     -      |     -     |   21.94  \n",
            "   1    |  2340   |   0.193439   |     -      |     -     |   21.96  \n",
            "   1    |  2360   |   0.151471   |     -      |     -     |   21.97  \n",
            "   1    |  2380   |   0.151174   |     -      |     -     |   21.95  \n",
            "   1    |  2400   |   0.201361   |     -      |     -     |   21.95  \n",
            "   1    |  2420   |   0.218865   |     -      |     -     |   21.96  \n",
            "   1    |  2440   |   0.137987   |     -      |     -     |   21.97  \n",
            "   1    |  2460   |   0.207317   |     -      |     -     |   21.95  \n",
            "   1    |  2480   |   0.166528   |     -      |     -     |   21.96  \n",
            "   1    |  2500   |   0.231847   |     -      |     -     |   21.95  \n",
            "   1    |  2520   |   0.153545   |     -      |     -     |   21.97  \n",
            "   1    |  2540   |   0.197147   |     -      |     -     |   21.96  \n",
            "   1    |  2560   |   0.144008   |     -      |     -     |   21.96  \n",
            "   1    |  2580   |   0.195893   |     -      |     -     |   21.97  \n",
            "   1    |  2600   |   0.166028   |     -      |     -     |   21.99  \n",
            "   1    |  2620   |   0.110181   |     -      |     -     |   21.96  \n",
            "   1    |  2640   |   0.197268   |     -      |     -     |   21.97  \n",
            "   1    |  2660   |   0.203985   |     -      |     -     |   21.97  \n",
            "   1    |  2680   |   0.155243   |     -      |     -     |   22.00  \n",
            "   1    |  2700   |   0.253355   |     -      |     -     |   21.97  \n",
            "   1    |  2720   |   0.196846   |     -      |     -     |   21.96  \n",
            "   1    |  2740   |   0.138748   |     -      |     -     |   21.95  \n",
            "   1    |  2760   |   0.148452   |     -      |     -     |   21.97  \n",
            "   1    |  2780   |   0.267237   |     -      |     -     |   21.96  \n",
            "   1    |  2800   |   0.160053   |     -      |     -     |   21.96  \n",
            "   1    |  2820   |   0.208688   |     -      |     -     |   21.97  \n",
            "   1    |  2840   |   0.241698   |     -      |     -     |   21.98  \n",
            "   1    |  2860   |   0.212634   |     -      |     -     |   21.96  \n",
            "   1    |  2880   |   0.123625   |     -      |     -     |   21.97  \n",
            "   1    |  2900   |   0.192621   |     -      |     -     |   21.95  \n",
            "   1    |  2920   |   0.186463   |     -      |     -     |   21.95  \n",
            "   1    |  2940   |   0.139564   |     -      |     -     |   21.96  \n",
            "   1    |  2960   |   0.198665   |     -      |     -     |   21.96  \n",
            "   1    |  2980   |   0.184118   |     -      |     -     |   21.96  \n",
            "   1    |  3000   |   0.199624   |     -      |     -     |   21.97  \n",
            "   1    |  3020   |   0.121280   |     -      |     -     |   22.15  \n",
            "   1    |  3040   |   0.203059   |     -      |     -     |   21.95  \n",
            "   1    |  3060   |   0.178834   |     -      |     -     |   21.94  \n",
            "   1    |  3080   |   0.190973   |     -      |     -     |   21.95  \n",
            "   1    |  3100   |   0.208176   |     -      |     -     |   21.95  \n",
            "   1    |  3120   |   0.207439   |     -      |     -     |   21.94  \n",
            "   1    |  3140   |   0.313202   |     -      |     -     |   21.92  \n",
            "   1    |  3160   |   0.145824   |     -      |     -     |   21.92  \n",
            "   1    |  3180   |   0.178383   |     -      |     -     |   21.96  \n",
            "   1    |  3200   |   0.153460   |     -      |     -     |   21.94  \n",
            "   1    |  3220   |   0.174432   |     -      |     -     |   21.96  \n",
            "   1    |  3240   |   0.191328   |     -      |     -     |   21.94  \n",
            "   1    |  3260   |   0.147358   |     -      |     -     |   21.95  \n",
            "   1    |  3280   |   0.178774   |     -      |     -     |   21.94  \n",
            "   1    |  3300   |   0.085331   |     -      |     -     |   21.95  \n",
            "   1    |  3320   |   0.205378   |     -      |     -     |   21.94  \n",
            "   1    |  3340   |   0.165404   |     -      |     -     |   21.97  \n",
            "   1    |  3360   |   0.179570   |     -      |     -     |   21.95  \n",
            "   1    |  3380   |   0.105583   |     -      |     -     |   21.94  \n",
            "   1    |  3400   |   0.161774   |     -      |     -     |   21.97  \n",
            "   1    |  3420   |   0.205431   |     -      |     -     |   21.97  \n",
            "   1    |  3440   |   0.157802   |     -      |     -     |   21.94  \n",
            "   1    |  3460   |   0.240074   |     -      |     -     |   21.96  \n",
            "   1    |  3480   |   0.211631   |     -      |     -     |   21.95  \n",
            "   1    |  3500   |   0.132040   |     -      |     -     |   21.95  \n",
            "   1    |  3520   |   0.185251   |     -      |     -     |   21.95  \n",
            "   1    |  3540   |   0.228171   |     -      |     -     |   21.94  \n",
            "   1    |  3560   |   0.193043   |     -      |     -     |   21.96  \n",
            "   1    |  3580   |   0.160655   |     -      |     -     |   21.96  \n",
            "   1    |  3600   |   0.173691   |     -      |     -     |   21.94  \n",
            "   1    |  3620   |   0.156211   |     -      |     -     |   21.95  \n",
            "   1    |  3640   |   0.130072   |     -      |     -     |   21.95  \n",
            "   1    |  3660   |   0.125053   |     -      |     -     |   21.96  \n",
            "   1    |  3680   |   0.197344   |     -      |     -     |   21.93  \n",
            "   1    |  3700   |   0.154903   |     -      |     -     |   21.96  \n",
            "   1    |  3720   |   0.177512   |     -      |     -     |   21.93  \n",
            "   1    |  3740   |   0.182230   |     -      |     -     |   21.96  \n",
            "   1    |  3760   |   0.181997   |     -      |     -     |   21.95  \n",
            "   1    |  3780   |   0.179302   |     -      |     -     |   21.97  \n",
            "   1    |  3800   |   0.198048   |     -      |     -     |   21.95  \n",
            "   1    |  3820   |   0.156898   |     -      |     -     |   21.98  \n",
            "   1    |  3840   |   0.187839   |     -      |     -     |   21.96  \n",
            "   1    |  3860   |   0.143651   |     -      |     -     |   21.95  \n",
            "   1    |  3880   |   0.191936   |     -      |     -     |   21.93  \n",
            "   1    |  3900   |   0.132934   |     -      |     -     |   21.97  \n",
            "   1    |  3920   |   0.148333   |     -      |     -     |   21.95  \n",
            "   1    |  3940   |   0.186119   |     -      |     -     |   21.93  \n",
            "   1    |  3950   |   0.112196   |     -      |     -     |   10.97  \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.230650   |  0.164136  |   93.91   |  4508.55 \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.145180   |     -      |     -     |   22.98  \n",
            "   2    |   40    |   0.110714   |     -      |     -     |   21.96  \n",
            "   2    |   60    |   0.143153   |     -      |     -     |   21.92  \n",
            "   2    |   80    |   0.123117   |     -      |     -     |   21.89  \n",
            "   2    |   100   |   0.108150   |     -      |     -     |   21.90  \n",
            "   2    |   120   |   0.103743   |     -      |     -     |   21.93  \n",
            "   2    |   140   |   0.096038   |     -      |     -     |   21.92  \n",
            "   2    |   160   |   0.191338   |     -      |     -     |   21.95  \n",
            "   2    |   180   |   0.101248   |     -      |     -     |   21.95  \n",
            "   2    |   200   |   0.094473   |     -      |     -     |   21.96  \n",
            "   2    |   220   |   0.139374   |     -      |     -     |   21.94  \n",
            "   2    |   240   |   0.144968   |     -      |     -     |   21.95  \n",
            "   2    |   260   |   0.083033   |     -      |     -     |   21.92  \n",
            "   2    |   280   |   0.090842   |     -      |     -     |   21.93  \n",
            "   2    |   300   |   0.167945   |     -      |     -     |   21.94  \n",
            "   2    |   320   |   0.116631   |     -      |     -     |   21.95  \n",
            "   2    |   340   |   0.106067   |     -      |     -     |   21.93  \n",
            "   2    |   360   |   0.142170   |     -      |     -     |   21.94  \n",
            "   2    |   380   |   0.127054   |     -      |     -     |   21.97  \n",
            "   2    |   400   |   0.077266   |     -      |     -     |   21.92  \n",
            "   2    |   420   |   0.108201   |     -      |     -     |   21.93  \n",
            "   2    |   440   |   0.117531   |     -      |     -     |   21.86  \n",
            "   2    |   460   |   0.082926   |     -      |     -     |   21.92  \n",
            "   2    |   480   |   0.135264   |     -      |     -     |   21.91  \n",
            "   2    |   500   |   0.145316   |     -      |     -     |   21.84  \n",
            "   2    |   520   |   0.165336   |     -      |     -     |   21.88  \n",
            "   2    |   540   |   0.099259   |     -      |     -     |   21.94  \n",
            "   2    |   560   |   0.120126   |     -      |     -     |   21.93  \n",
            "   2    |   580   |   0.125786   |     -      |     -     |   21.92  \n",
            "   2    |   600   |   0.157852   |     -      |     -     |   21.91  \n",
            "   2    |   620   |   0.091053   |     -      |     -     |   21.96  \n",
            "   2    |   640   |   0.112530   |     -      |     -     |   21.94  \n",
            "   2    |   660   |   0.051630   |     -      |     -     |   21.96  \n",
            "   2    |   680   |   0.078661   |     -      |     -     |   21.94  \n",
            "   2    |   700   |   0.102026   |     -      |     -     |   21.95  \n",
            "   2    |   720   |   0.145293   |     -      |     -     |   21.94  \n",
            "   2    |   740   |   0.097189   |     -      |     -     |   21.95  \n",
            "   2    |   760   |   0.127492   |     -      |     -     |   21.94  \n",
            "   2    |   780   |   0.114219   |     -      |     -     |   21.96  \n",
            "   2    |   800   |   0.184828   |     -      |     -     |   21.94  \n",
            "   2    |   820   |   0.133249   |     -      |     -     |   21.95  \n",
            "   2    |   840   |   0.127867   |     -      |     -     |   21.95  \n",
            "   2    |   860   |   0.102913   |     -      |     -     |   21.97  \n",
            "   2    |   880   |   0.131074   |     -      |     -     |   21.94  \n",
            "   2    |   900   |   0.154670   |     -      |     -     |   21.95  \n",
            "   2    |   920   |   0.131709   |     -      |     -     |   21.93  \n",
            "   2    |   940   |   0.054681   |     -      |     -     |   21.94  \n",
            "   2    |   960   |   0.157236   |     -      |     -     |   21.93  \n",
            "   2    |   980   |   0.093712   |     -      |     -     |   21.94  \n",
            "   2    |  1000   |   0.131358   |     -      |     -     |   21.95  \n",
            "   2    |  1020   |   0.055299   |     -      |     -     |   21.95  \n",
            "   2    |  1040   |   0.102267   |     -      |     -     |   21.91  \n",
            "   2    |  1060   |   0.121660   |     -      |     -     |   21.92  \n",
            "   2    |  1080   |   0.138773   |     -      |     -     |   21.92  \n",
            "   2    |  1100   |   0.102143   |     -      |     -     |   21.94  \n",
            "   2    |  1120   |   0.096919   |     -      |     -     |   21.95  \n",
            "   2    |  1140   |   0.124359   |     -      |     -     |   21.95  \n",
            "   2    |  1160   |   0.091130   |     -      |     -     |   21.92  \n",
            "   2    |  1180   |   0.065056   |     -      |     -     |   21.92  \n",
            "   2    |  1200   |   0.146490   |     -      |     -     |   21.95  \n",
            "   2    |  1220   |   0.155573   |     -      |     -     |   21.93  \n",
            "   2    |  1240   |   0.088402   |     -      |     -     |   21.91  \n",
            "   2    |  1260   |   0.053120   |     -      |     -     |   21.96  \n",
            "   2    |  1280   |   0.064167   |     -      |     -     |   21.92  \n",
            "   2    |  1300   |   0.133306   |     -      |     -     |   21.94  \n",
            "   2    |  1320   |   0.223660   |     -      |     -     |   21.94  \n",
            "   2    |  1340   |   0.122800   |     -      |     -     |   21.93  \n",
            "   2    |  1360   |   0.069643   |     -      |     -     |   21.95  \n",
            "   2    |  1380   |   0.126772   |     -      |     -     |   21.93  \n",
            "   2    |  1400   |   0.150471   |     -      |     -     |   21.93  \n",
            "   2    |  1420   |   0.154494   |     -      |     -     |   21.93  \n",
            "   2    |  1440   |   0.097364   |     -      |     -     |   21.94  \n",
            "   2    |  1460   |   0.160247   |     -      |     -     |   21.94  \n",
            "   2    |  1480   |   0.112462   |     -      |     -     |   21.94  \n",
            "   2    |  1500   |   0.067369   |     -      |     -     |   21.96  \n",
            "   2    |  1520   |   0.093808   |     -      |     -     |   21.96  \n",
            "   2    |  1540   |   0.170102   |     -      |     -     |   21.96  \n",
            "   2    |  1560   |   0.113868   |     -      |     -     |   21.95  \n",
            "   2    |  1580   |   0.095633   |     -      |     -     |   21.93  \n",
            "   2    |  1600   |   0.112113   |     -      |     -     |   21.96  \n",
            "   2    |  1620   |   0.112363   |     -      |     -     |   21.93  \n",
            "   2    |  1640   |   0.069817   |     -      |     -     |   21.93  \n",
            "   2    |  1660   |   0.083805   |     -      |     -     |   21.94  \n",
            "   2    |  1680   |   0.094680   |     -      |     -     |   21.95  \n",
            "   2    |  1700   |   0.089425   |     -      |     -     |   21.94  \n",
            "   2    |  1720   |   0.090647   |     -      |     -     |   21.92  \n",
            "   2    |  1740   |   0.134494   |     -      |     -     |   21.96  \n",
            "   2    |  1760   |   0.132385   |     -      |     -     |   21.98  \n",
            "   2    |  1780   |   0.095208   |     -      |     -     |   21.98  \n",
            "   2    |  1800   |   0.082947   |     -      |     -     |   22.00  \n",
            "   2    |  1820   |   0.057509   |     -      |     -     |   21.99  \n",
            "   2    |  1840   |   0.195227   |     -      |     -     |   21.99  \n",
            "   2    |  1860   |   0.120729   |     -      |     -     |   22.01  \n",
            "   2    |  1880   |   0.119206   |     -      |     -     |   22.00  \n",
            "   2    |  1900   |   0.175002   |     -      |     -     |   22.00  \n",
            "   2    |  1920   |   0.098775   |     -      |     -     |   21.99  \n",
            "   2    |  1940   |   0.105117   |     -      |     -     |   21.97  \n",
            "   2    |  1960   |   0.091894   |     -      |     -     |   21.99  \n",
            "   2    |  1980   |   0.074362   |     -      |     -     |   22.01  \n",
            "   2    |  2000   |   0.093006   |     -      |     -     |   21.97  \n",
            "   2    |  2020   |   0.130613   |     -      |     -     |   21.99  \n",
            "   2    |  2040   |   0.132904   |     -      |     -     |   21.97  \n",
            "   2    |  2060   |   0.067733   |     -      |     -     |   21.97  \n",
            "   2    |  2080   |   0.093784   |     -      |     -     |   21.98  \n",
            "   2    |  2100   |   0.068591   |     -      |     -     |   21.98  \n",
            "   2    |  2120   |   0.112789   |     -      |     -     |   21.98  \n",
            "   2    |  2140   |   0.177619   |     -      |     -     |   22.00  \n",
            "   2    |  2160   |   0.117941   |     -      |     -     |   22.01  \n",
            "   2    |  2180   |   0.103373   |     -      |     -     |   22.00  \n",
            "   2    |  2200   |   0.130659   |     -      |     -     |   22.00  \n",
            "   2    |  2220   |   0.119021   |     -      |     -     |   21.98  \n",
            "   2    |  2240   |   0.111976   |     -      |     -     |   22.00  \n",
            "   2    |  2260   |   0.120988   |     -      |     -     |   22.00  \n",
            "   2    |  2280   |   0.100361   |     -      |     -     |   22.00  \n",
            "   2    |  2300   |   0.104208   |     -      |     -     |   22.00  \n",
            "   2    |  2320   |   0.084012   |     -      |     -     |   22.00  \n",
            "   2    |  2340   |   0.104667   |     -      |     -     |   22.01  \n",
            "   2    |  2360   |   0.111407   |     -      |     -     |   22.01  \n",
            "   2    |  2380   |   0.118883   |     -      |     -     |   22.00  \n",
            "   2    |  2400   |   0.057060   |     -      |     -     |   22.00  \n",
            "   2    |  2420   |   0.113461   |     -      |     -     |   21.99  \n",
            "   2    |  2440   |   0.093429   |     -      |     -     |   22.03  \n",
            "   2    |  2460   |   0.083399   |     -      |     -     |   22.03  \n",
            "   2    |  2480   |   0.091998   |     -      |     -     |   22.03  \n",
            "   2    |  2500   |   0.126809   |     -      |     -     |   21.99  \n",
            "   2    |  2520   |   0.081756   |     -      |     -     |   22.01  \n",
            "   2    |  2540   |   0.209568   |     -      |     -     |   21.99  \n",
            "   2    |  2560   |   0.105980   |     -      |     -     |   22.00  \n",
            "   2    |  2580   |   0.033977   |     -      |     -     |   22.00  \n",
            "   2    |  2600   |   0.128377   |     -      |     -     |   22.00  \n",
            "   2    |  2620   |   0.097687   |     -      |     -     |   22.00  \n",
            "   2    |  2640   |   0.057061   |     -      |     -     |   22.01  \n",
            "   2    |  2660   |   0.107963   |     -      |     -     |   22.01  \n",
            "   2    |  2680   |   0.049760   |     -      |     -     |   22.02  \n",
            "   2    |  2700   |   0.131782   |     -      |     -     |   22.02  \n",
            "   2    |  2720   |   0.118616   |     -      |     -     |   22.03  \n",
            "   2    |  2740   |   0.134702   |     -      |     -     |   22.00  \n",
            "   2    |  2760   |   0.095436   |     -      |     -     |   22.01  \n",
            "   2    |  2780   |   0.081847   |     -      |     -     |   22.01  \n",
            "   2    |  2800   |   0.080153   |     -      |     -     |   22.01  \n",
            "   2    |  2820   |   0.098618   |     -      |     -     |   22.02  \n",
            "   2    |  2840   |   0.144366   |     -      |     -     |   22.01  \n",
            "   2    |  2860   |   0.117280   |     -      |     -     |   22.01  \n",
            "   2    |  2880   |   0.107751   |     -      |     -     |   22.02  \n",
            "   2    |  2900   |   0.058485   |     -      |     -     |   22.01  \n",
            "   2    |  2920   |   0.081230   |     -      |     -     |   22.00  \n",
            "   2    |  2940   |   0.087219   |     -      |     -     |   22.01  \n",
            "   2    |  2960   |   0.125347   |     -      |     -     |   22.00  \n",
            "   2    |  2980   |   0.166208   |     -      |     -     |   22.01  \n",
            "   2    |  3000   |   0.092213   |     -      |     -     |   22.00  \n",
            "   2    |  3020   |   0.144450   |     -      |     -     |   21.97  \n",
            "   2    |  3040   |   0.088824   |     -      |     -     |   22.00  \n",
            "   2    |  3060   |   0.122526   |     -      |     -     |   21.97  \n",
            "   2    |  3080   |   0.091055   |     -      |     -     |   21.99  \n",
            "   2    |  3100   |   0.095961   |     -      |     -     |   22.00  \n",
            "   2    |  3120   |   0.093098   |     -      |     -     |   21.95  \n",
            "   2    |  3140   |   0.104924   |     -      |     -     |   21.95  \n",
            "   2    |  3160   |   0.092697   |     -      |     -     |   21.96  \n",
            "   2    |  3180   |   0.128438   |     -      |     -     |   21.97  \n",
            "   2    |  3200   |   0.077342   |     -      |     -     |   21.95  \n",
            "   2    |  3220   |   0.059430   |     -      |     -     |   21.97  \n",
            "   2    |  3240   |   0.120320   |     -      |     -     |   22.00  \n",
            "   2    |  3260   |   0.043702   |     -      |     -     |   21.96  \n",
            "   2    |  3280   |   0.068763   |     -      |     -     |   21.94  \n",
            "   2    |  3300   |   0.079453   |     -      |     -     |   21.94  \n",
            "   2    |  3320   |   0.093541   |     -      |     -     |   21.94  \n",
            "   2    |  3340   |   0.080236   |     -      |     -     |   21.94  \n",
            "   2    |  3360   |   0.137400   |     -      |     -     |   21.93  \n",
            "   2    |  3380   |   0.127890   |     -      |     -     |   21.95  \n",
            "   2    |  3400   |   0.039036   |     -      |     -     |   21.95  \n",
            "   2    |  3420   |   0.089798   |     -      |     -     |   21.96  \n",
            "   2    |  3440   |   0.100441   |     -      |     -     |   21.94  \n",
            "   2    |  3460   |   0.096765   |     -      |     -     |   21.93  \n",
            "   2    |  3480   |   0.036206   |     -      |     -     |   21.95  \n",
            "   2    |  3500   |   0.131871   |     -      |     -     |   21.93  \n",
            "   2    |  3520   |   0.088605   |     -      |     -     |   21.93  \n",
            "   2    |  3540   |   0.099399   |     -      |     -     |   21.94  \n",
            "   2    |  3560   |   0.072769   |     -      |     -     |   21.92  \n",
            "   2    |  3580   |   0.092720   |     -      |     -     |   21.91  \n",
            "   2    |  3600   |   0.158309   |     -      |     -     |   21.93  \n",
            "   2    |  3620   |   0.034789   |     -      |     -     |   21.92  \n",
            "   2    |  3640   |   0.101047   |     -      |     -     |   21.94  \n",
            "   2    |  3660   |   0.114057   |     -      |     -     |   21.95  \n",
            "   2    |  3680   |   0.077646   |     -      |     -     |   21.97  \n",
            "   2    |  3700   |   0.090548   |     -      |     -     |   21.93  \n",
            "   2    |  3720   |   0.104040   |     -      |     -     |   21.94  \n",
            "   2    |  3740   |   0.128369   |     -      |     -     |   21.90  \n",
            "   2    |  3760   |   0.117078   |     -      |     -     |   21.89  \n",
            "   2    |  3780   |   0.095092   |     -      |     -     |   21.89  \n",
            "   2    |  3800   |   0.062190   |     -      |     -     |   21.91  \n",
            "   2    |  3820   |   0.080320   |     -      |     -     |   21.89  \n",
            "   2    |  3840   |   0.031625   |     -      |     -     |   21.89  \n",
            "   2    |  3860   |   0.140653   |     -      |     -     |   21.92  \n",
            "   2    |  3880   |   0.152421   |     -      |     -     |   21.93  \n",
            "   2    |  3900   |   0.080413   |     -      |     -     |   21.92  \n",
            "   2    |  3920   |   0.037755   |     -      |     -     |   21.91  \n",
            "   2    |  3940   |   0.070527   |     -      |     -     |   21.91  \n",
            "   2    |  3950   |   0.029423   |     -      |     -     |   10.96  \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.107249   |  0.162614  |   95.43   |  4509.54 \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'trained-distilbert-base-uncased-emotion-BiGRU.sav'\n",
        "pickle.dump(bert_classifier, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "Pi0d0Im5QxvH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading the model (to avoid retraining in reruns)\n",
        "\n",
        "# import pickle\n",
        "# filename = 'trained-distilbert-base-uncased-emotion.sav'\n",
        "# f = open(filename, 'rb')\n",
        "# bert_classifier = pickle.load(f)"
      ],
      "metadata": {
        "id": "2lW22lySva8l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = evaluate(bert_classifier, val_dataloader)\n",
        "print(\"Val Loss: \" + str(val_loss))\n",
        "print(\"Val Accuracy: \" + str(val_accuracy))"
      ],
      "metadata": {
        "id": "F3FUYQDxKpME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7821c3-9bff-4223-fbee-463a67dc78a6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1626144042266374\n",
            "Val Accuracy: 95.42613636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "Y84FNM8rlMuq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc, precision_score, recall_score\n",
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'ROC AUC: {roc_auc:.4f}')\n",
        "\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    precision_c, recall_c, _ = precision_recall_curve(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    pr_auc = auc(precision_c, recall_c)\n",
        "    print(f'P-R AUC: {pr_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "    #Get Precision and Recall over the test set\n",
        "    precision  = precision_score(y_true, y_pred, average='binary')\n",
        "    print(f'Precision: {precision*100:.2f}%')\n",
        "    recall = recall_score(y_true, y_pred, average='binary')\n",
        "    print(f'Recall: {recall*100:.2f}%')\n",
        "    print('RoBERTa-Base-BiLSTM: f1=%.3f ' % (f1))\n",
        "\n",
        "    # Plot ROC AUC\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # plot the precision-recall curves\n",
        "    plt.plot(precision_c, recall_c, 'b', label = 'AUC = %0.2f' % pr_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.xlabel('Precision')\n",
        "    plt.ylabel('Recall')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "BaP0b0jclMxY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute predicted probabilities on the validation set\n",
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "id": "MUH-ejXRlMz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "metadata": {
        "id": "Yvvheq0qlM3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"no-negative tweets ratio \", preds.sum()/len(preds))"
      ],
      "metadata": {
        "id": "ENShAjsVlh0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Bert classifier for unseen test data\n",
        "evaluate_roc(probs, y_test)"
      ],
      "metadata": {
        "id": "4nMBgpwvlh3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 1"
      ],
      "metadata": {
        "id": "zqirCmYuuYPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.text.values\n",
        "y = df1.sentiment.values\n",
        "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "blHSYaz9rWGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN =  280\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"
      ],
      "metadata": {
        "id": "LHkD3v3DrWJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "PFgGW0g7rWMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42) \n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "id": "C15aScZ7rWQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "id": "BV8qdxdorWW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "metadata": {
        "id": "IWA5L_vXrWZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"no-negative tweets ratio \", preds.sum()/len(preds))"
      ],
      "metadata": {
        "id": "vmU48X_wrWcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Bert classifier for unseen test data\n",
        "evaluate_roc(probs, y_test)"
      ],
      "metadata": {
        "id": "q2J_5WbYrWe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 2"
      ],
      "metadata": {
        "id": "__XHLDr7sXzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2.text.values\n",
        "y = df2.sentiment.values\n",
        "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "KL4fvGwtsfMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN =  280\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"
      ],
      "metadata": {
        "id": "UWZaHaRHsfMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "E9HVAST2sfMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42) \n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "id": "0DgNVgLYstSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "id": "wsQvAkT3stSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "metadata": {
        "id": "Rfb1hZkNstSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"no-negative tweets ratio \", preds.sum()/len(preds))"
      ],
      "metadata": {
        "id": "k9kl_X-NstSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Bert classifier for unseen test data\n",
        "evaluate_roc(probs, y_test)"
      ],
      "metadata": {
        "id": "CIYUYUDxstSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uCx1zoZpsihF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 3"
      ],
      "metadata": {
        "id": "9P3Sl4TyskJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df3.text.values\n",
        "y = df3.sentiment.values\n",
        "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "NJaYb6qVsmgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN =  280\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"
      ],
      "metadata": {
        "id": "cDP6Aq1lsmgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "mGH5uKTBsmgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42) \n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "id": "Ohu1X0l4sv_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "id": "ehKs_Hoasv_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "metadata": {
        "id": "zWWGeZrEsv_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"no-negative tweets ratio \", preds.sum()/len(preds))"
      ],
      "metadata": {
        "id": "NnilNQbIsv_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Bert classifier for unseen test data\n",
        "evaluate_roc(probs, y_test)"
      ],
      "metadata": {
        "id": "MkPnUPx3sv_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mLr3anZ4siof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 4"
      ],
      "metadata": {
        "id": "EaM6piRas1XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df4.text.values\n",
        "y = df4.sentiment.values\n",
        "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "RbrKWSI3s91p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN =  280\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"
      ],
      "metadata": {
        "id": "fxx7ZTm1s91q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "T_vwMKHbs91r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42) \n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "id": "sCo5YrVZs2jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "id": "HUp-hx4vs2jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "metadata": {
        "id": "D8_J4ZsEs2jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"no-negative tweets ratio \", preds.sum()/len(preds))"
      ],
      "metadata": {
        "id": "rSoWoSPZs2jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Bert classifier for unseen test data\n",
        "evaluate_roc(probs, y_test)"
      ],
      "metadata": {
        "id": "qSqZKD1vs2jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QFJkGQigsits"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 5"
      ],
      "metadata": {
        "id": "niWG8neUs4No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df5.text.values\n",
        "y = df5.sentiment.values\n",
        "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "SQV4jrVms_90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN =  280\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]], version=\"base\", text_preprocessing_fn=text_preprocessing)[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train, version=\"base\", text_preprocessing_fn=text_preprocessing)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val, version=\"base\", text_preprocessing_fn=text_preprocessing)"
      ],
      "metadata": {
        "id": "unFyjf8os_91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "OBSt28hOs_92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42) \n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2, version=\"base\")\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "metadata": {
        "id": "CyEj0m9ms56o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "metadata": {
        "id": "FJz8jcOQs56p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "metadata": {
        "id": "hx1c_2xbs56q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.5\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"no-negative tweets ratio \", preds.sum()/len(preds))"
      ],
      "metadata": {
        "id": "2dz6at6Ys56q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Bert classifier for unseen test data\n",
        "evaluate_roc(probs, y_test)"
      ],
      "metadata": {
        "id": "UGl5A0X0s56q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}